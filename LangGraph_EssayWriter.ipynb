{
 "cells": [
  {
   "cell_type": "code",
   "id": "f6174a51-f385-420c-9658-9aafa0b44de7",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec93e65f-2454-471b-ba38-8520bca44ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b895924-33e7-4e6a-987a-540126e56260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:35:03.335294Z",
     "start_time": "2025-02-22T19:35:03.058974Z"
    }
   },
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TypedDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mAgentState\u001B[39;00m(\u001B[43mTypedDict\u001B[49m):\n\u001B[1;32m      2\u001B[0m     task: \u001B[38;5;28mstr\u001B[39m\n\u001B[1;32m      3\u001B[0m     plan: \u001B[38;5;28mstr\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'TypedDict' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f357250f-3783-4d26-8d5d-1387a96d830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=config[\"OPEN_AI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0925b73e-138f-4800-8d80-d28d3cc92689",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b99c45a6-134e-46cc-bb21-bb0a168d10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60c52771-0b9e-4e44-a941-b9f00202c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "715a831e-c1cf-47cb-99e6-ff1aae898d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "290bd9d8-0e0f-4f9f-9ac2-c24a18502d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3aba018-5f61-4b09-81d1-1dfa17da9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9303e6de-2948-435e-8eec-8d2e8f82f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6663f2d0-3c2f-4d59-b887-5a2704ad24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d541f993-46c1-49bf-b882-d08c4086cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2af4cb00-8b16-4bcd-9ab5-1ed6ed7e986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af3c8dd1-4521-41f4-8d8a-0a087ee7000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b61d1481-4ae6-4a30-83bd-d1736eb3b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d97f1f80-2e7e-4209-a722-2a2286ff66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f4e0b72-65ce-4983-8f31-f9ffe7569f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6b0eb14-aba2-45da-afaf-6c19cae8ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "609fff9e-9156-49dd-9a85-4d87c904a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa6e2873-66fc-4303-acc6-3b8eb62fe068",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa3e8990-cd6a-45c2-9f0f-0abd1e7575a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1782cfe-11d6-4f40-a11b-b860e518356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "efc8172a-f668-4c3c-99a3-55793e5c216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': \"I. Introduction\\n    A. Brief overview of Langchain and Langsmith\\n    B. Thesis statement: Exploring the differences between Langchain and Langsmith\\n\\nII. Langchain\\n    A. Definition and purpose\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and limitations\\n\\nIII. Langsmith\\n    A. Definition and purpose\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and limitations\\n\\nIV. Comparison between Langchain and Langsmith\\n    A. Technology stack\\n    B. Scalability and performance\\n    C. Security and privacy\\n    D. Adoption and popularity\\n    E. Future prospects\\n\\nV. Conclusion\\n    A. Recap of key differences between Langchain and Langsmith\\n    B. Implications for the future of blockchain technology\\n    C. Final thoughts and recommendations\\n\\nNotes:\\n- Ensure a balanced comparison between Langchain and Langsmith.\\n- Provide examples and real-world applications to support the differences outlined.\\n- Consider the target audience's familiarity with blockchain technology when explaining technical terms.\"}}\n",
      "{'research_plan': {'content': ['Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', \"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', 'Enter LangChain and LangSmith. In this post, we will explore the latest product by the team that created Langchain (the most popular LLM software tool) and see what new parts of the LLM stack ...', 'LangSmith supports a powerful comparison view that lets you hone in on key differences, regressions, and improvements between different experiments. Open the comparison view To open the comparison view, select two or more experiments from the \"Experiments\" tab from a given dataset page. Then, click on the \"Compare\" button at the bottom of the page.', 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.']}}\n",
      "{'generate': {'draft': \"**Title: Langchain vs Langsmith: Contrasting Two Leading AI Language Model Platforms**\\n\\nI. Introduction\\nIn the realm of AI language models, Langchain and Langsmith stand out as prominent platforms with distinct features and capabilities. While both serve the purpose of enabling applications utilizing large language models, they differ significantly in their approaches and functionalities.\\n\\nII. Langchain\\nLangchain is a versatile open-source framework designed to facilitate the development of applications leveraging large language models like GPT-3. With a focus on flexibility and ease of use, Langchain offers a range of key features such as seamless integration with Python, extensive use cases in natural language processing, and the ability to certify skills through the Finxter Academy. Despite its advantages, Langchain may have limitations in terms of scalability for extremely large projects.\\n\\nIII. Langsmith\\nOn the other hand, Langsmith emerges as a robust platform that excels in testing, debugging, evaluating, and monitoring language learning models (LLMs). By providing a plethora of features for in-depth analysis, Langsmith caters to the needs of developers and researchers in the AI domain. Accessible through a simple sign-up process, Langsmith offers a comprehensive toolkit for enhancing the performance of LLM applications.\\n\\nIV. Comparison between Langchain and Langsmith\\nA. Technology Stack:\\n   - Langchain primarily focuses on building applications with large language models.\\n   - Langsmith, in contrast, emphasizes testing, debugging, and evaluating LLMs.\\n\\nB. Scalability and Performance:\\n   - Langchain may face limitations in scalability for extensive projects due to its framework design.\\n   - Langsmith's emphasis on testing and monitoring enhances performance but may not be as versatile for direct application development.\\n\\nC. Security and Privacy:\\n   - Both platforms prioritize data security and privacy, ensuring user information and models are safeguarded.\\n\\nD. Adoption and Popularity:\\n   - Langchain, known for its versatility, has gained popularity among developers seeking to integrate LLMs into their projects.\\n   - Langsmith's focus on testing and evaluation has attracted a niche audience interested in fine-tuning LLM applications.\\n\\nE. Future Prospects:\\n   - The future of Langchain lies in expanding its scalability and diversifying its use cases to cater to a broader audience.\\n   - Langsmith is poised to enhance its features for more comprehensive testing and debugging capabilities, potentially attracting a wider user base.\\n\\nV. Conclusion\\nIn conclusion, the comparison between Langchain and Langsmith reveals the unique strengths and focus areas of each platform. While Langchain excels in application development with LLMs, Langsmith stands out for its testing and evaluation capabilities. Understanding these differences is crucial for developers and researchers looking to leverage AI language models effectively in their projects, paving the way for advancements in the field of natural language processing.\", 'revision_number': 2}}\n",
      "{'reflect': {'critique': \"**Overall Feedback:**\\nThe essay provides a clear and structured comparison between Langchain and Langsmith, highlighting their key features, strengths, and differences. The introduction effectively sets the stage for the comparison, and the conclusion succinctly summarizes the main points discussed. However, there are areas where the essay can be improved to enhance its depth and clarity.\\n\\n**Content and Analysis:**\\n1. **Depth and Detail:** While the essay covers the basic features of Langchain and Langsmith, it would benefit from a more in-depth analysis of their functionalities, user experiences, and real-world applications. Providing specific examples or case studies could help illustrate the platforms' capabilities more effectively.\\n   \\n2. **Technical Comparison:** Consider delving deeper into the technical aspects of both platforms, such as their architecture, algorithms used, performance benchmarks, and community support. This would provide a more comprehensive understanding of their capabilities and limitations.\\n\\n3. **User Experience:** Include information on the user interface, documentation quality, support resources, and community engagement for both Langchain and Langsmith. Evaluating these aspects can give readers insights into the usability and accessibility of the platforms.\\n\\n**Structure and Organization:**\\n1. **Section Development:** Each section could be expanded to provide more detailed insights into the features, strengths, and limitations of Langchain and Langsmith. Consider breaking down the comparison into sub-sections for a more structured analysis.\\n\\n2. **Transition and Flow:** Ensure smooth transitions between paragraphs and sections to maintain the coherence of the essay. Use transition phrases to guide readers through the comparison process seamlessly.\\n\\n**Style and Clarity:**\\n1. **Clarity of Language:** The essay uses clear and concise language, which is commendable. However, consider incorporating more technical terms and industry-specific jargon to cater to a more specialized audience interested in AI language models.\\n\\n2. **Engagement:** To enhance reader engagement, consider incorporating anecdotes, quotes from experts, or current trends in AI language model development. This can make the essay more dynamic and relevant to the evolving landscape of AI technology.\\n\\n**Recommendations:**\\n1. **Expand on Features:** Provide a more detailed breakdown of the features offered by Langchain and Langsmith, including specific tools, APIs, and integrations that set them apart.\\n\\n2. **Include Case Studies:** Incorporate real-world examples or case studies showcasing how developers or researchers have utilized Langchain and Langsmith in their projects. This can add practical insights to the comparison.\\n\\n3. **Technical Insights:** Dive deeper into the technical specifications of both platforms, discussing their underlying technologies, model architectures, and performance metrics to offer a more comprehensive analysis.\\n\\n4. **User Perspective:** Consider including user testimonials or reviews to offer a user-centric perspective on the usability, effectiveness, and overall satisfaction with Langchain and Langsmith.\\n\\n5. **Future Outlook:** Provide a more detailed analysis of the potential future developments, updates, and trends for Langchain and Langsmith, considering how they might evolve to meet the changing demands of the AI industry.\\n\\nBy incorporating these recommendations, you can enrich the essay with more detailed insights, technical analysis, and user perspectives, making it a more comprehensive and informative comparison of Langchain and Langsmith.\"}}\n",
      "{'research_critique': {'content': ['Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', \"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', 'Enter LangChain and LangSmith. In this post, we will explore the latest product by the team that created Langchain (the most popular LLM software tool) and see what new parts of the LLM stack ...', 'LangSmith supports a powerful comparison view that lets you hone in on key differences, regressions, and improvements between different experiments. Open the comparison view To open the comparison view, select two or more experiments from the \"Experiments\" tab from a given dataset page. Then, click on the \"Compare\" button at the bottom of the page.', 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', 'Table 3: Component overview: actions orchestration\\nTable 4: Component overview: memory management\\nTable 5: Component overview: reusable components\\nTable 6: Component overview: prompt templates\\nTable 7: Component overview: document loaders\\nTable 8: Component overview: document transformation and splitting\\nTable 9: Component overview: construct sequence of calls\\nTable 10: Component overview: vector store\\nTable 11: Component overview: retriever\\nTable 12: Component overview: model I/O\\nTable 13: Component overview: data connection\\nConclusion\\nAs the landscape of LLMs continues to evolve, the choice of framework becomes a crucial decision for developers venturing into the realm of building sophisticated AI applications. Sign up\\nSign in\\nSign up\\nSign in\\nHarnessing the power of Large Language Models: A comparative overview of LangChain, Semantic Kernel, AutoGen and more\\nJane Huang\\nFollow\\nData Science at Microsoft\\n--\\nListen\\nShare\\nBy Jane Huang and Kirk Li\\nIn this article, we delve into a comparative analysis of diverse strategies for developing applications empowered by Large Language Models (LLMs), encompassing OpenAI’s Assistant API, frameworks like LangChain, Semantic Kernel, AutoGen, and more. Additionally, Matthew Bolanos articulates a forward-looking vision for the future of Semantic Kernel by incorporating OpenAI assistants, as well as instructions in his series of publications “OpenAI Assistants: The Future of Semantic Kernel,” “OpenAI Assistants: a first look into using OpenAI Assistants with Semantic Kernel,” and “OpenAI Assistants: The power of templated assistant instructions” on Microsoft’s platform. Here are a few examples:\\nComponents of the frameworks\\nNext, let’s embark on a more in-depth exploration by scrutinizing and comparing the various components of the frameworks as shown in Tables 3–13.\\n To accomplish this, members of Microsoft’s semantic kernel team are utilizing the research findings from the AutoGen team to develop an abstraction capable of accommodating a wide range of experiences, including scenarios where agents collaborate as a team.\\n', 'LangSmith Walkthrough. LangChain makes it easy to prototype LLM applications and Agents. However, delivering LLM applications to production can be deceptively difficult. You will have to iterate on your prompts, chains, and other components to build a high-quality product. LangSmith makes it easy to debug, test, and continuously improve your ...', 'Technical reference that covers components, APIs, and other aspects of LangSmith. API reference LangSmith API Reference; SDK reference LangChain off-the-shelf evaluators (Python only) Data formats Run (span) data format; Feedback data format; Trace query syntax. Filter arguments; Filter query language; Authentication and authorization', \"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", \"LangSmith User Guide. LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we'll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them ...\"]}}\n",
      "{'generate': {'draft': '**Title: Langchain vs Langsmith: Contrasting Two Leading AI Language Model Frameworks**\\n\\n**I. Introduction**\\nIn the realm of AI language model frameworks, Langchain and Langsmith stand out as prominent tools. This essay aims to dissect and compare the unique features of Langchain and Langsmith to provide a comprehensive understanding of their differences.\\n\\n**II. Langchain**\\nA. *Definition and Purpose*: Langchain is an open-source framework designed to facilitate the development of applications using large language models like GPT-3.\\nB. *Key Features and Characteristics*: Discuss the specific features that make Langchain a preferred choice for developers.\\nC. *Use Cases and Applications*: Explore real-world examples where Langchain has been successfully implemented.\\nD. *Advantages and Limitations*: Highlight the strengths and weaknesses of Langchain in practical applications.\\n\\n**III. Langsmith**\\nA. *Definition and Purpose*: Langsmith is a platform tailored for LLM application development, monitoring, and testing.\\nB. *Key Features and Characteristics*: Detail the distinguishing features that set Langsmith apart from other frameworks.\\nC. *Use Cases and Applications*: Provide instances where Langsmith has excelled in enhancing AI applications.\\nD. *Advantages and Limitations*: Evaluate the advantages and drawbacks of utilizing Langsmith in AI development projects.\\n\\n**IV. Comparison between Langchain and Langsmith**\\nA. *Technology Stack*: Contrast the underlying technologies utilized by Langchain and Langsmith.\\nB. *Scalability and Performance*: Analyze how each framework handles scalability and performance optimization.\\nC. *Security and Privacy*: Discuss the security measures embedded in Langchain and Langsmith to safeguard user data.\\nD. *Adoption and Popularity*: Compare the adoption rates and popularity of Langchain and Langsmith within the developer community.\\nE. *Future Prospects*: Predict the future trajectory of Langchain and Langsmith based on current trends and advancements in AI technology.\\n\\n**V. Conclusion**\\nA. *Recap of Key Differences*: Summarize the main disparities between Langchain and Langsmith for clarity.\\nB. *Implications for the Future*: Reflect on how the distinctions between these frameworks may shape the future landscape of AI development.\\nC. *Final Thoughts and Recommendations*: Offer conclusive insights and recommendations for developers considering Langchain or Langsmith for their projects.\\n\\nThis structured essay will provide a detailed and balanced comparison between Langchain and Langsmith, catering to both technical and non-technical audiences.', 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377de99-03b0-402d-9655-b12055faec42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
