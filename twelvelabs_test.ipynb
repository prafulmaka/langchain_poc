{
 "cells": [
  {
   "cell_type": "code",
   "id": "b9b1c579-2878-4226-bf90-ec885a9c0d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T04:41:50.780136Z",
     "start_time": "2025-11-30T04:41:50.777473Z"
    }
   },
   "source": [
    "# Twelvelabs"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:35:32.184159Z",
     "start_time": "2025-12-02T09:35:32.181094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from grp import struct_group\n",
    "from typing import List\n",
    "from dotenv import dotenv_values\n",
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.types import VideoSegment\n",
    "from twelvelabs.embed import TasksStatusResponse\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "config = dotenv_values(\".env\")"
   ],
   "id": "84c1655777cc1e8a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "c5b749f04aa0c6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:35:19.823788Z",
     "start_time": "2025-12-02T09:35:08.162980Z"
    }
   },
   "source": [
    "\n",
    "# 1. Initialize the client\n",
    "client = TwelveLabs(api_key=config[\"TWELVELABS_API_KEY\"])\n",
    "\n",
    "# 2. Upload a video\n",
    "with open(\"pushup.MOV\", \"rb\") as video_file:\n",
    "    task = client.embed.tasks.create(\n",
    "        model_name=\"marengo3.0\",\n",
    "        video_file=video_file, # Or use video_file to upload a file from the local file system\n",
    "        # video_clip_length=5,\n",
    "        # video_start_offset_sec=30,\n",
    "        # video_end_offset_sec=60,\n",
    "        # video_embedding_scope=[\"clip\", \"video\"]\n",
    "    )\n",
    "print(f\"Created video embedding task: id={task.id}\")\n",
    "\n",
    "# 3. Monitor the status\n",
    "def on_task_update(task: TasksStatusResponse):\n",
    "    print(f\"  Status={task.status}\")\n",
    "\n",
    "status = client.embed.tasks.wait_for_done(sleep_interval=5, task_id=task.id, callback=on_task_update)\n",
    "print(f\"Embedding done: {status.status}\")\n",
    "\n",
    "# 4. Retrieve the embeddings\n",
    "task = client.embed.tasks.retrieve(\n",
    "    task_id=task.id,\n",
    "    embedding_option=[\"visual\", \"audio\", \"transcription\"]\n",
    ")\n",
    "\n",
    "# 5. Process the results\n",
    "def print_segments(segments: List[VideoSegment], max_elements: int = 5):\n",
    "    for segment in segments:\n",
    "        print(f\"  embedding_scope={segment.embedding_scope} embedding_option={segment.embedding_option} start_offset_sec={segment.start_offset_sec} end_offset_sec={segment.end_offset_sec}\")\n",
    "        first_few = segment.float_[:max_elements]\n",
    "        print(\n",
    "            f\"  embeddings: [{', '.join(str(x) for x in first_few)}...] (total: {len(segment.float_)} values)\"\n",
    "        )\n",
    "\n",
    "\n",
    "if task.video_embedding is not None and task.video_embedding.segments is not None:\n",
    "    print_segments(task.video_embedding.segments)\n",
    "\n",
    "    segments = task.video_embedding.segments\n",
    "    metadata = task.video_embedding.metadata\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created video embedding task: id=692eb2cd54939c83c1d476c8\n",
      "  Status=processing\n",
      "  Status=ready\n",
      "Embedding done: ready\n",
      "  embedding_scope=clip embedding_option=audio start_offset_sec=0.0 end_offset_sec=6.0\n",
      "  embeddings: [0.067871094, -0.032958984, -0.11230469, 0.040039062, 0.02722168...] (total: 512 values)\n",
      "  embedding_scope=clip embedding_option=audio start_offset_sec=6.0 end_offset_sec=12.0\n",
      "  embeddings: [0.040039062, -0.076171875, -0.046142578, 0.018676758, 0.053466797...] (total: 512 values)\n",
      "  embedding_scope=clip embedding_option=audio start_offset_sec=12.0 end_offset_sec=19.5\n",
      "  embeddings: [0.06591797, -0.048583984, -0.083984375, 0.045898438, 0.037597656...] (total: 512 values)\n",
      "  embedding_scope=clip embedding_option=visual start_offset_sec=0.0 end_offset_sec=6.0\n",
      "  embeddings: [0.026489258, 0.026855469, -0.0138549805, 0.078125, -0.0022735596...] (total: 512 values)\n",
      "  embedding_scope=clip embedding_option=visual start_offset_sec=6.0 end_offset_sec=12.0\n",
      "  embeddings: [0.0064086914, 0.05444336, 0.015563965, 0.07763672, -0.026733398...] (total: 512 values)\n",
      "  embedding_scope=clip embedding_option=visual start_offset_sec=12.0 end_offset_sec=19.5\n",
      "  embeddings: [0.0390625, 0.044433594, -0.018676758, 0.06982422, -0.011962891...] (total: 512 values)\n",
      "  embedding_scope=clip embedding_option=transcription start_offset_sec=0.0 end_offset_sec=6.0\n",
      "  embeddings: [-0.020385742, -0.04711914, -0.0546875, 0.041503906, 0.018310547...] (total: 512 values)\n",
      "  embedding_scope=clip embedding_option=transcription start_offset_sec=12.0 end_offset_sec=19.5\n",
      "  embeddings: [-0.06689453, -0.07861328, -0.072265625, 0.037353516, -0.0040893555...] (total: 512 values)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T19:45:30.823768Z",
     "start_time": "2025-11-21T19:45:30.817926Z"
    }
   },
   "cell_type": "code",
   "source": "# Load to Pinecone",
   "id": "160c4a43878d7a1f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:36:28.301749Z",
     "start_time": "2025-12-02T09:36:28.258080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pc = Pinecone(api_key=config[\"PINECONE_API_KEY\"])\n",
    "\n",
    "index = pc.Index(host=\"https://gymogul-videos-kuv1rfi.svc.aped-4627-b74a.pinecone.io\")"
   ],
   "id": "13fc2bb93a0837f0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramaka/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T20:15:27.642661Z",
     "start_time": "2025-11-21T20:15:27.637813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create vector metadata list\n",
    "\n",
    "video_id = \"review\"\n",
    "\n",
    "vectors = []\n",
    "\n",
    "for idx, seg in enumerate(segments):\n",
    "    vectors.append({\n",
    "        \"id\": f\"{video_id}-{idx}\",\n",
    "        \"values\": seg.float_,\n",
    "        \"metadata\": {\n",
    "            \"video_id\": video_id,\n",
    "            \"start\": seg.start_offset_sec,\n",
    "            \"end\": seg.end_offset_sec\n",
    "        }\n",
    "    })\n"
   ],
   "id": "59e4955cfb2ff145",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T20:15:57.097896Z",
     "start_time": "2025-11-21T20:15:55.866134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Upsert to Pinecone\n",
    "\n",
    "index.upsert(vectors)"
   ],
   "id": "81f0e68482955c24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 8}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:48:03.151846Z",
     "start_time": "2025-11-25T03:48:02.872040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.types import BaseSegment\n",
    "\n",
    "# 2. Create text embeddings\n",
    "res = client.embed.create(\n",
    "    model_name=\"marengo3.0\",\n",
    "    text=\"What is the video about? What does the man say?\",\n",
    ")\n",
    "\n",
    "\n"
   ],
   "id": "af8d58de18e02415",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:48:04.421448Z",
     "start_time": "2025-11-25T03:48:04.418948Z"
    }
   },
   "cell_type": "code",
   "source": "question_vectors = res.text_embedding.segments[0].float_",
   "id": "14a4ea7584b5a2aa",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:48:06.200274Z",
     "start_time": "2025-11-25T03:48:05.758353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index.query(\n",
    "    namespace=\"__default__\",\n",
    "    vector=question_vectors,\n",
    "    top_k=3,\n",
    "    include_metadata=True,\n",
    "    include_values=False\n",
    ")"
   ],
   "id": "19d2658c797a2a72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'pushup:7',\n",
       "              'metadata': {'end': 19.5,\n",
       "                           'start': 12.0,\n",
       "                           'transcript': 'The man holds the plank position for '\n",
       "                                         'several seconds before pushing off '\n",
       "                                         'the ground with his hands. He '\n",
       "                                         'returns to a standing position, '\n",
       "                                         'completing the exercise.',\n",
       "                           'video_id': 'pushup'},\n",
       "              'score': 0.483910918,\n",
       "              'values': []},\n",
       "             {'id': 'pushup:6',\n",
       "              'metadata': {'end': 6.0,\n",
       "                           'start': 0.0,\n",
       "                           'transcript': 'A man in black shorts and a black '\n",
       "                                         't-shirt stands with his feet '\n",
       "                                         'together, then bends down and places '\n",
       "                                         'his hands on the floor. He lowers '\n",
       "                                         'his body into a plank position, '\n",
       "                                         'holding it briefly.',\n",
       "                           'video_id': 'pushup'},\n",
       "              'score': 0.437577695,\n",
       "              'values': []},\n",
       "             {'id': 'pushup:2',\n",
       "              'metadata': {'end': 19.5,\n",
       "                           'start': 12.0,\n",
       "                           'transcript': 'The man holds the plank position for '\n",
       "                                         'several seconds before pushing off '\n",
       "                                         'the ground with his hands. He '\n",
       "                                         'returns to a standing position, '\n",
       "                                         'completing the exercise.',\n",
       "                           'video_id': 'pushup'},\n",
       "              'score': 0.0340870097,\n",
       "              'values': []}],\n",
       " 'namespace': '__default__',\n",
       " 'usage': {'read_units': 1}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T18:35:33.838075Z",
     "start_time": "2025-11-22T18:35:32.112781Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "execution_count": 41,
   "source": [
    "# To delete Pinecone vectors\n",
    "\n",
    "# for count in range(0,8):\n",
    "#     print(count)\n",
    "#     index.delete(ids=f\"pushup-{count}\", namespace=\"__default__\")"
   ],
   "id": "5d3f2dc0399ec567"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T17:14:51.334136Z",
     "start_time": "2025-11-25T17:14:51.313214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a Pegasus enabled index\n",
    "\n",
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.indexes import IndexesCreateRequestModelsItem\n",
    "from twelvelabs.tasks import TasksRetrieveResponse\n",
    "\n",
    "# Initialize the client\n",
    "client = TwelveLabs(api_key=config[\"TWELVELABS_API_KEY\"])\n",
    "\n",
    "index = client.indexes.create(\n",
    "    index_name=\"pegasus-index\",\n",
    "    models=[\n",
    "        IndexesCreateRequestModelsItem(\n",
    "            model_name=\"pegasus1.2\", model_options=[\"visual\", \"audio\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(f\"Created index: id={index.id}\")\n",
    "\n",
    "# task = client.tasks.create(\n",
    "#     index_id=index.id,\n",
    "#     video_url=\"<YOUR_VIDEO_URL>\" # Or use video_file to upload a file from the local file system\n",
    "#     )\n",
    "# print(f\"Created task: id={task.id}\")\n",
    "#\n",
    "# def on_task_update(task: TasksRetrieveResponse):\n",
    "#     print(f\"  Status={task.status}\")\n",
    "#\n",
    "# task = client.tasks.wait_for_done(task_id=task.id, callback=on_task_update)\n",
    "# if task.status != \"ready\":\n",
    "#     raise RuntimeError(f\"Indexing failed with status {task.status}\")\n",
    "# print(\n",
    "#     f\"Upload complete. The unique identifier of your video is {task.video_id}.\")\n",
    "#\n",
    "# gist = client.gist(video_id=task.video_id,types=[\"title\", \"topic\", \"hashtag\"])\n",
    "# print(f\"Title={gist.title}\\nTopics={gist.topics}\\nHashtags={gist.hashtags}\")\n"
   ],
   "id": "f4ebdee6b930af0b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T06:09:20.192711Z",
     "start_time": "2025-11-30T06:09:20.188500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def get_pegasus_transcript(client: TwelveLabs, pegasus_index_id: str, video_path: str):\n",
    "\n",
    "    # 2. Upload a video\n",
    "    with open(video_path, \"rb\") as video_file:\n",
    "        # 1) Upload to Pegasus-enabled index\n",
    "        task = client.tasks.create(\n",
    "            index_id=pegasus_index_id,\n",
    "            video_file=video_file\n",
    "        )\n",
    "\n",
    "    task = client.tasks.wait_for_done(task_id=task.id)\n",
    "\n",
    "    if task.status != \"ready\":\n",
    "        raise RuntimeError(f\"Pegasus indexing failed or not ready. Status={task.status}\")\n",
    "\n",
    "    video_id = task.video_id  # this is what analyze() uses\n",
    "\n",
    "    # 2) Ask Pegasus for a rich, time-stamped transcript in JSON\n",
    "    # Weâ€™ll use open-ended analyze() with a JSON schema so it returns structured text.\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"segments\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"start_sec\": {\"type\": \"number\"},\n",
    "                        \"end_sec\": {\"type\": \"number\"},\n",
    "                        \"text\": {\"type\": \"string\"},\n",
    "                    },\n",
    "                    \"required\": [\"start_sec\", \"end_sec\", \"text\"],\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"segments\"],\n",
    "    }\n",
    "\n",
    "    prompt = (\n",
    "        \"Create a detailed summary of this video.\"\n",
    "        \"For each segment, return JSON with: start_sec, end_sec, text. \"\n",
    "        \"Use the original language, keep sentences complete, and ensure timestamps \"\n",
    "        \"are monotonically increasing and aligned with the video timeline.\"\n",
    "    )\n",
    "\n",
    "    res = client.analyze(\n",
    "        video_id=video_id,\n",
    "        prompt=prompt,\n",
    "        temperature=0.1,\n",
    "        response_format={\"type\": \"json_schema\", \"json_schema\": schema},\n",
    "        max_tokens=4000,\n",
    "    )\n",
    "    # res.data is a JSON string per docs :contentReference[oaicite:4]{index=4}\n",
    "    parsed = json.loads(res.data)\n",
    "    return parsed[\"segments\"]  # list of {start_sec, end_sec, text}"
   ],
   "id": "8a8e4081e619d306",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T06:09:23.514628Z",
     "start_time": "2025-11-30T06:09:23.512375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transcript_for_segment(transcript_segments, start, end):\n",
    "    \"\"\"Concatenate transcript text that overlaps [start, end].\"\"\"\n",
    "    chunks = []\n",
    "    for t in transcript_segments:\n",
    "        if t[\"end_sec\"] <= start:\n",
    "            continue\n",
    "        if t[\"start_sec\"] >= end:\n",
    "            break\n",
    "        chunks.append(t[\"text\"])\n",
    "    return \" \".join(chunks).strip()"
   ],
   "id": "4e7f1b8476368d1b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T06:09:24.394228Z",
     "start_time": "2025-11-30T06:09:24.390674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "def ingest_video_to_pinecone(\n",
    "    client: TwelveLabs,\n",
    "    pegasus_index_id: str,\n",
    "    video_path: str,\n",
    "    video_id: str,   # your own ID (filename, UUID, etc.)\n",
    "):\n",
    "\n",
    "    # 2) Pegasus transcript (time-coded)\n",
    "    transcript_segments = get_pegasus_transcript(client, pegasus_index_id, video_path)\n",
    "\n",
    "    # 3) Build vectors with per-segment transcript\n",
    "    vectors = []\n",
    "    for idx, seg in enumerate(segments):\n",
    "        start = seg.start_offset_sec\n",
    "        end = seg.end_offset_sec\n",
    "        snippet = transcript_for_segment(transcript_segments, start, end)\n",
    "\n",
    "        vectors.append({\n",
    "            \"id\": f\"{video_id}:{idx}\",\n",
    "            \"values\": seg.float_,\n",
    "            \"metadata\": {\n",
    "                \"video_id\": video_id,\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"transcript\": snippet,\n",
    "            },\n",
    "        })\n",
    "\n",
    "    # 4) Upsert to Pinecone\n",
    "    # index.upsert(vectors=vectors)\n",
    "\n",
    "    return vectors"
   ],
   "id": "f8bdc7c685b06c10",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T06:10:23.798121Z",
     "start_time": "2025-11-30T06:09:31.320898Z"
    }
   },
   "cell_type": "code",
   "source": "vectors = ingest_video_to_pinecone(client=client, pegasus_index_id=\"69220af621611291fd429500\", video_path=\"pushup.MOV\", video_id=\"review\")",
   "id": "a09e65539abc3795",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:38:49.650169Z",
     "start_time": "2025-11-25T03:38:49.573139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feed matches to LLM chat model\n",
    "\n",
    "matches = index.query(\n",
    "    namespace=\"__default__\",\n",
    "    vector=question_vectors,\n",
    "    top_k=3,\n",
    "    include_metadata=True,\n",
    "    include_values=False\n",
    ")"
   ],
   "id": "99cd7a74dde61060",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:38:51.753851Z",
     "start_time": "2025-11-25T03:38:51.748729Z"
    }
   },
   "cell_type": "code",
   "source": "matches",
   "id": "2bf35a03b4af7df9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'pushup:7',\n",
       "              'metadata': {'end': 19.5,\n",
       "                           'start': 12.0,\n",
       "                           'transcript': 'The man holds the plank position for '\n",
       "                                         'several seconds before pushing off '\n",
       "                                         'the ground with his hands. He '\n",
       "                                         'returns to a standing position, '\n",
       "                                         'completing the exercise.',\n",
       "                           'video_id': 'pushup'},\n",
       "              'score': 0.483910918,\n",
       "              'values': []},\n",
       "             {'id': 'pushup:6',\n",
       "              'metadata': {'end': 6.0,\n",
       "                           'start': 0.0,\n",
       "                           'transcript': 'A man in black shorts and a black '\n",
       "                                         't-shirt stands with his feet '\n",
       "                                         'together, then bends down and places '\n",
       "                                         'his hands on the floor. He lowers '\n",
       "                                         'his body into a plank position, '\n",
       "                                         'holding it briefly.',\n",
       "                           'video_id': 'pushup'},\n",
       "              'score': 0.437577695,\n",
       "              'values': []},\n",
       "             {'id': 'pushup:2',\n",
       "              'metadata': {'end': 19.5,\n",
       "                           'start': 12.0,\n",
       "                           'transcript': 'The man holds the plank position for '\n",
       "                                         'several seconds before pushing off '\n",
       "                                         'the ground with his hands. He '\n",
       "                                         'returns to a standing position, '\n",
       "                                         'completing the exercise.',\n",
       "                           'video_id': 'pushup'},\n",
       "              'score': 0.0340870097,\n",
       "              'values': []}],\n",
       " 'namespace': '__default__',\n",
       " 'usage': {'read_units': 1}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:35:41.101934Z",
     "start_time": "2025-12-02T09:35:40.690738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import langchain\n",
    "langchain.verbose = False\n",
    "# langchain.debug = False\n",
    "# langchain.llm_cache = False\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1-mini\", model_provider=\"openai\", api_key=config[\"OPEN_AI_KEY\"])"
   ],
   "id": "99567b2810adb938",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:38:58.823421Z",
     "start_time": "2025-12-02T09:38:58.497845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to embed text > to feed to Pinecone index.query\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def get_embedding_video(text, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Generates a vector embedding for the given text using OpenAI's model.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \") # Best practice is to replace newlines\n",
    "    response = client.embed.create(\n",
    "        model_name=\"marengo3.0\",\n",
    "        text=text\n",
    "    )\n",
    "    # The embedding is in the 'data' array of the response\n",
    "    return response.text_embedding.segments[0].float_\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"What is the review about? Which product are they talking about?\"\n",
    "embedding_vector = get_embedding_video(sentence)\n",
    "\n",
    "print(f\"Original sentence: {sentence}\")\n",
    "print(f\"Embedding vector (first 50 dimensions): {embedding_vector[:50]}...\")\n",
    "print(f\"Vector dimension: {len(embedding_vector)}\")\n"
   ],
   "id": "ea62a0cb3f7625c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: What is the review about? Which product are they talking about?\n",
      "Embedding vector (first 50 dimensions): [-0.02319336, -0.13574219, -0.10888672, 0.029785156, -0.035888672, 0.055908203, -0.09863281, -0.08691406, 0.043701172, 0.013916016, 0.028442383, 0.06347656, 0.012145996, 0.00793457, 0.061767578, 0.059326172, -0.033935547, -0.041748047, -0.033447266, -0.1015625, 0.04638672, 0.092285156, -0.000831604, 0.037109375, -0.0234375, -0.004425049, -0.02355957, 0.041992188, -0.012390137, -0.007446289, -0.0546875, 0.04736328, -0.055908203, 0.006072998, -0.09033203, 0.0037994385, -0.053466797, 0.045410156, 0.02722168, 0.033203125, 0.010986328, -0.09863281, 0.09863281, -0.052246094, 0.010375977, 0.012390137, 0.04248047, -0.036865234, 0.056396484, 0.034179688]...\n",
      "Vector dimension: 512\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:41:02.581723Z",
     "start_time": "2025-12-02T09:41:01.669042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to embed text > to feed to Pinecone index.query\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def get_embedding_text(text, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Generates a vector embedding for the given text using OpenAI's model.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=config[\"OPEN_AI_KEY\"])\n",
    "\n",
    "    text = text.replace(\"\\n\", \" \") # Best practice is to replace newlines\n",
    "    response = client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    # The embedding is in the 'data' array of the response\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"The Rolex Yachtmaster 40 was first released in 1992. The current reference number 126622 is $12,500 USD. It features a 40 mm oyster case in oystersteel and platinum.\"\n",
    "embedding_vector = get_embedding_text(sentence)\n",
    "\n",
    "print(f\"Original sentence: {sentence}\")\n",
    "print(f\"Embedding vector (first 50 dimensions): {embedding_vector[:50]}...\")\n",
    "print(f\"Vector dimension: {len(embedding_vector)}\")\n"
   ],
   "id": "5b72d03d15a115e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: The Rolex Yachtmaster 40 was first released in 1992. The current reference number 126622 is $12,500 USD. It features a 40 mm oyster case in oystersteel and platinum.\n",
      "Embedding vector (first 50 dimensions): [0.006935261655598879, 0.037173446267843246, -0.013058535754680634, 0.03287992626428604, -0.036461565643548965, -0.048808224499225616, -0.016795901581645012, 0.03497106954455376, -0.029454005882143974, -0.01055583544075489, -0.00029424112290143967, 0.0012916716514155269, 0.03216804563999176, 0.002591685624793172, 0.037039969116449356, -0.017574520781636238, -0.008014203980565071, -0.0106058893725276, -0.09645964205265045, -5.852669710293412e-05, -0.03975400701165199, -0.022457566112279892, -0.041266750544309616, 0.009348977357149124, -0.02776329219341278, -0.008164365775883198, -0.006896330509334803, -0.002861421089619398, 0.005124974530190229, -0.018219660967588425, 0.0003378645924385637, -0.009421277791261673, -0.04707301780581474, 0.03474860638380051, -0.008231104351580143, 0.01612851582467556, -0.00835901964455843, -0.028764372691512108, 0.00752478651702404, -0.06042075529694557, 0.015839314088225365, 0.0348820835351944, -0.004376945085823536, 0.0026250549126416445, 0.0419786311686039, -0.05339094623923302, -0.04362485185265541, 0.04222334176301956, -0.028452925384044647, 0.029276035726070404]...\n",
      "Vector dimension: 3072\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:46:39.162356Z",
     "start_time": "2025-12-02T09:46:39.156930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# v2\n",
    "\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "\n",
    "    # Get embedding for message\n",
    "    embedding_video = get_embedding_video(last_query)\n",
    "    embedding_text = get_embedding_text(last_query)\n",
    "\n",
    "    # Perform search against Pinecone\n",
    "    response_video = pc.Index(host=\"https://gymogul-videos-kuv1rfi.svc.aped-4627-b74a.pinecone.io\").query(\n",
    "        namespace=\"__default__\",\n",
    "        vector=embedding_video,\n",
    "        top_k=3,\n",
    "        include_metadata=True,\n",
    "        include_values=False\n",
    "    )\n",
    "\n",
    "    response_text = pc.Index(host=\"https://test-index-3-kuv1rfi.svc.aped-4627-b74a.pinecone.io\").query(\n",
    "    namespace=\"text\",\n",
    "    vector=embedding_text,\n",
    "    top_k=3,\n",
    "    include_metadata=True,\n",
    "    include_values=False\n",
    "    )\n",
    "\n",
    "    response = response_video['matches'] + response_text['matches']\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{response}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context])"
   ],
   "id": "bf80392c100c4292",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:47:06.049511Z",
     "start_time": "2025-12-02T09:47:01.732700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "messages = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the review about? Which product are they talking about? How much does it cost?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "result = agent.invoke(messages)"
   ],
   "id": "3d9a86da9ac90d70",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:47:06.702918Z",
     "start_time": "2025-12-02T09:47:06.699772Z"
    }
   },
   "cell_type": "code",
   "source": "result['messages'][-1].content",
   "id": "1b0488d28a240c21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The review is about the Rolex Yachtmaster 40 watch. It features a 40 mm diameter face, a two-tone (polished center link) bracelet, and a design that sits beautifully on the wrist with curved edges and subtle crown details. The current reference number for the Rolex Yachtmaster 40 is 126622, and it costs $12,500 USD. It has an oyster case made of oystersteel and platinum.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3357cc1eddc3dab4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
