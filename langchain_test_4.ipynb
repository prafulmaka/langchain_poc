{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c7938c-e37e-42c8-9ffc-010fc3e89437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T15:20:43.201020Z",
     "start_time": "2025-10-21T15:20:43.199190Z"
    }
   },
   "outputs": [],
   "source": [
    "# ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "325d8fe4-5019-4ecb-84c7-a9cc64798ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env PINECONE_API_KEY=\n",
    "\n",
    "# %env PINECONE_API_KEY\n",
    "\n",
    "# %env OPENAI_API_KEY=\n",
    "# %env OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903c7116-a64a-4cdd-bc25-7b53bfb8e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a0d756-734e-407f-8504-16972b757c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "\n",
    "client = OpenAI(api_key=config[\"OPEN_AI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fb9a8ff-2109-4730-a110-0098fdacc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1-mini\", model_provider=\"openai\", api_key=config[\"OPEN_AI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfcd01d5-84f1-418b-bc93-8f5c54aef8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, Bob! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'finish_reason': 'stop', 'logprobs': None}, id='run--258fc923-09ed-4f07-bec0-9f8243200855-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7391a05-be01-43b8-973d-40cfb9e2b397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I donâ€™t know your name based on our current conversation. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 11, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'finish_reason': 'stop', 'logprobs': None}, id='run--52f909d5-1adc-433f-a020-0bb3f5eea596-0', usage_metadata={'input_tokens': 11, 'output_tokens': 19, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What's my name?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10074069-5db1-4754-b6ce-a9690c545500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have access to your personal information unless you share it with me. What would you like me to call you?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 11, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'finish_reason': 'stop', 'logprobs': None}, id='run--a5225aa9-f01e-4204-9dba-06ef98520ed6-0', usage_metadata={'input_tokens': 11, 'output_tokens': 24, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d44587a-5e37-4f45-ba88-3bd4b96b6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a SIMPLE example of how we can store chat history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a8046c3-136f-4878-8f77-846966fc73e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Bob! I can analyze and interpret images you share with me, including individual frames extracted from a video. However, I don't have the capability to process video files directly or handle continuous video streams. If you extract specific frames from your video and upload them as images, I can certainly help analyze those! Let me know how you'd like to proceed.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 26, 'total_tokens': 96, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'finish_reason': 'stop', 'logprobs': None}, id='run--717fb43c-f755-4b28-a423-7874a5310d35-0', usage_metadata={'input_tokens': 26, 'output_tokens': 70, 'total_tokens': 96, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "        # AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"Are you able to process image frames from a video?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c8f046b-9461-4b98-95e0-7764e6dba6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how we can process images and use in LangChain messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aea7c79-7adb-4358-91b2-386827197708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, seconds_per_frame=2):\n",
    "    base64Frames = []\n",
    "    base_video_path, _ = os.path.splitext(video_path)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frames_to_skip = int(fps * seconds_per_frame)\n",
    "    curr_frame=0\n",
    "\n",
    "    # Loop through the video and extract frames at specified sampling rate\n",
    "    while curr_frame < total_frames - 1:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "        curr_frame += frames_to_skip\n",
    "    video.release()\n",
    "\n",
    "    print(f\"Extracted {len(base64Frames)} frames\")\n",
    "    return base64Frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab9fd82-a75f-4ef3-aca6-1594dd67796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 21 frames\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import base64\n",
    "video_path = \"pushup.MOV\"\n",
    "base64Frames = process_video(video_path, seconds_per_frame=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "526d065a-470d-4187-aad3-aabc58c4a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are generating a video summary. Please provide a summary of the video. Respond in Markdown.\"),\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"Please analyze the frames from this video and tell me what is happening.\"},\n",
    "            *[\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{frame}\"},\n",
    "                }\n",
    "                for frame in base64Frames\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca7d9092-7767-4f72-b6b5-a18e8f9a08d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"These frames depict a sequence where a person performs an exercise or workout routine involving a transition from standing to a crawling-like position and then moving into a plank or push-up position. Here's what is happening step-by-step:\\n\\n1. The person starts in a standing position with knees bent.\\n2. They prepare for movement by slightly leaning forward.\\n3. They bend down further, placing their hands closer to the floor.\\n4. The person places their hands on the floor while maintaining a bent-knee position.\\n5-11. The person shifts their weight forward, moving the body into a plank position, possibly transitioning between a crouch and a push-up/plank.\\n12-14. The person appears to be in a full plank or push-up position.\\n15. The person shifts back or finishes the plank position.\\n16-17. The person moves back to a crouched position.\\n18-19. The person stands back up and faces the camera with a slight smile.\\n\\nOverall, it looks like an exercise involving dynamic movement from standing to crawling/plank and back, perhaps to build strength or practice a specific calisthenics move. The final frame showing a smile indicates the person might be wrapping up or pleased with their performance.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 246, 'prompt_tokens': 51368, 'total_tokens': 51614, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'finish_reason': 'stop', 'logprobs': None}, id='run--66531a51-dc39-418e-b4cc-b54b636bc729-0', usage_metadata={'input_tokens': 51368, 'output_tokens': 246, 'total_tokens': 51614, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f63529-6361-4c24-90c4-909d9235391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can try this approach to remove any heavy HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19483a2e-7537-453f-b19f-02e59f7d769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are generating a video summary. Please provide a summary of the video. Respond in Markdown.\"),\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"Please analyze the frames from this video and tell me what is happening.\"},\n",
    "            *[\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{frame}\"},\n",
    "                }\n",
    "                for frame in base64Frames\n",
    "            ]\n",
    "        ]\n",
    "    ),\n",
    "    HumanMessage(content=\"My name is Allison. What is your name?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31ed428e-fa0e-4dcf-a87b-26cd0ba4b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the heavy image message\n",
    "for msg in messages:\n",
    "    if isinstance(msg.content, list):\n",
    "        messages.remove(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a08ea835-1afb-4a1a-a434-7b1616f6d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone POC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "99558c22-8778-48fd-b199-38f8a1ddd5f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pinecone POC\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# pc = Pinecone(api_key=config[\"PINECONE_API_KEY\"])\n",
    "\n",
    "pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d9eaa105-943a-42d5-a916-2b3b2317183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "\n",
    "index_name = \"test-index-3\"\n",
    "openai_embedding_dimension = 3072\n",
    "\n",
    "\n",
    "# Two seperate approaches to creating an index on Pinecone\n",
    "\n",
    "# if not pc.has_index(index_name):\n",
    "#     pc.create_index_for_model(\n",
    "#         name=index_name,\n",
    "#         cloud=\"aws\",\n",
    "#         region=\"us-east-1\",\n",
    "#         embed={\n",
    "#             \"model\":\"text-embedding-3-large\",\n",
    "#             \"field_map\":{\"text\": \"chunk_text\"}\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=openai_embedding_dimension,  # Set the dimension manually\n",
    "        metric=\"cosine\",  # Specify the similarity metric\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "388c8f92-90e1-4d3c-a9bd-dc92dabc54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset\n",
    "\n",
    "records = [\n",
    "    { \"_id\": \"rec1\", \"chunk_text\": \"The Eiffel Tower was completed in 1889 and stands in Paris, France.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec2\", \"chunk_text\": \"Photosynthesis allows plants to convert sunlight into energy.\", \"category\": \"science\" },\n",
    "    { \"_id\": \"rec3\", \"chunk_text\": \"Albert Einstein developed the theory of relativity.\", \"category\": \"science\" },\n",
    "    { \"_id\": \"rec4\", \"chunk_text\": \"The mitochondrion is often called the powerhouse of the cell.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec5\", \"chunk_text\": \"Shakespeare wrote many famous plays, including Hamlet and Macbeth.\", \"category\": \"literature\" },\n",
    "    { \"_id\": \"rec6\", \"chunk_text\": \"Water boils at 100Â°C under standard atmospheric pressure.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec7\", \"chunk_text\": \"The Great Wall of China was built to protect against invasions.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec8\", \"chunk_text\": \"Honey never spoils due to its low moisture content and acidity.\", \"category\": \"food science\" },\n",
    "    { \"_id\": \"rec9\", \"chunk_text\": \"The speed of light in a vacuum is approximately 299,792 km/s.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec10\", \"chunk_text\": \"Newton's laws describe the motion of objects.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec11\", \"chunk_text\": \"The human brain has approximately 86 billion neurons.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec12\", \"chunk_text\": \"The Amazon Rainforest is one of the most biodiverse places on Earth.\", \"category\": \"geography\" },\n",
    "    { \"_id\": \"rec13\", \"chunk_text\": \"Black holes have gravitational fields so strong that not even light can escape.\", \"category\": \"astronomy\" },\n",
    "    { \"_id\": \"rec14\", \"chunk_text\": \"The periodic table organizes elements based on their atomic number.\", \"category\": \"chemistry\" },\n",
    "    { \"_id\": \"rec15\", \"chunk_text\": \"Leonardo da Vinci painted the Mona Lisa.\", \"category\": \"art\" },\n",
    "    { \"_id\": \"rec16\", \"chunk_text\": \"The internet revolutionized communication and information sharing.\", \"category\": \"technology\" },\n",
    "    { \"_id\": \"rec17\", \"chunk_text\": \"The Pyramids of Giza are among the Seven Wonders of the Ancient World.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec18\", \"chunk_text\": \"Dogs have an incredible sense of smell, much stronger than humans.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec19\", \"chunk_text\": \"The Pacific Ocean is the largest and deepest ocean on Earth.\", \"category\": \"geography\" },\n",
    "    { \"_id\": \"rec20\", \"chunk_text\": \"Chess is a strategic game that originated in India.\", \"category\": \"games\" },\n",
    "    { \"_id\": \"rec21\", \"chunk_text\": \"The Statue of Liberty was a gift from France to the United States.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec22\", \"chunk_text\": \"Coffee contains caffeine, a natural stimulant.\", \"category\": \"food science\" },\n",
    "    { \"_id\": \"rec23\", \"chunk_text\": \"Thomas Edison invented the practical electric light bulb.\", \"category\": \"inventions\" },\n",
    "    { \"_id\": \"rec24\", \"chunk_text\": \"The moon influences ocean tides due to gravitational pull.\", \"category\": \"astronomy\" },\n",
    "    { \"_id\": \"rec25\", \"chunk_text\": \"DNA carries genetic information for all living organisms.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec26\", \"chunk_text\": \"Rome was once the center of a vast empire.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec27\", \"chunk_text\": \"The Wright brothers pioneered human flight in 1903.\", \"category\": \"inventions\" },\n",
    "    { \"_id\": \"rec28\", \"chunk_text\": \"Bananas are a good source of potassium.\", \"category\": \"nutrition\" },\n",
    "    { \"_id\": \"rec29\", \"chunk_text\": \"The stock market fluctuates based on supply and demand.\", \"category\": \"economics\" },\n",
    "    { \"_id\": \"rec30\", \"chunk_text\": \"A compass needle points toward the magnetic north pole.\", \"category\": \"navigation\" },\n",
    "    { \"_id\": \"rec31\", \"chunk_text\": \"The universe is expanding, according to the Big Bang theory.\", \"category\": \"astronomy\" },\n",
    "    { \"_id\": \"rec32\", \"chunk_text\": \"Elephants have excellent memory and strong social bonds.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec33\", \"chunk_text\": \"The violin is a string instrument commonly used in orchestras.\", \"category\": \"music\" },\n",
    "    { \"_id\": \"rec34\", \"chunk_text\": \"The heart pumps blood throughout the human body.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec35\", \"chunk_text\": \"Ice cream melts when exposed to heat.\", \"category\": \"food science\" },\n",
    "    { \"_id\": \"rec36\", \"chunk_text\": \"Solar panels convert sunlight into electricity.\", \"category\": \"technology\" },\n",
    "    { \"_id\": \"rec37\", \"chunk_text\": \"The French Revolution began in 1789.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec38\", \"chunk_text\": \"The Taj Mahal is a mausoleum built by Emperor Shah Jahan.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec39\", \"chunk_text\": \"Rainbows are caused by light refracting through water droplets.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec40\", \"chunk_text\": \"Mount Everest is the tallest mountain in the world.\", \"category\": \"geography\" },\n",
    "    { \"_id\": \"rec41\", \"chunk_text\": \"Octopuses are highly intelligent marine creatures.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec42\", \"chunk_text\": \"The speed of sound is around 343 meters per second in air.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec43\", \"chunk_text\": \"Gravity keeps planets in orbit around the sun.\", \"category\": \"astronomy\" },\n",
    "    { \"_id\": \"rec44\", \"chunk_text\": \"The Mediterranean diet is considered one of the healthiest in the world.\", \"category\": \"nutrition\" },\n",
    "    { \"_id\": \"rec45\", \"chunk_text\": \"A haiku is a traditional Japanese poem with a 5-7-5 syllable structure.\", \"category\": \"literature\" },\n",
    "    { \"_id\": \"rec46\", \"chunk_text\": \"The human body is made up of about 60% water.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec47\", \"chunk_text\": \"The Industrial Revolution transformed manufacturing and transportation.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec48\", \"chunk_text\": \"Vincent van Gogh painted Starry Night.\", \"category\": \"art\" },\n",
    "    { \"_id\": \"rec49\", \"chunk_text\": \"Airplanes fly due to the principles of lift and aerodynamics.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec50\", \"chunk_text\": \"Renewable energy sources include wind, solar, and hydroelectric power.\", \"category\": \"energy\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ae327221-45c0-48a1-9eaa-49f043286d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset\n",
    "\n",
    "records = [\n",
    "    { \"_id\": \"rec51\", \"chunk_text\": \"Maka Projects is a holding company that owns multiple multi-billion dollar companies including Chedr, Gymogul and Coach Central.\", \"category\": \"business\" },\n",
    "    { \"_id\": \"rec52\", \"chunk_text\": \"Palantir is a software company specializing in data analytics and integration platforms, primarily serving government and commercial clients. Its technology, including the platforms Gotham and Foundry, helps organizations analyze and integrate data from disparate sources to improve decision-making.\", \"category\": \"business\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8554adde-a8ac-4732-a7dd-cdac113741db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format records\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "documents = []\n",
    "for record in records:\n",
    "    # Use 'chunk_text' as the page_content for embedding\n",
    "    page_content = record[\"chunk_text\"]\n",
    "    \n",
    "    # Store all other fields, including the original '_id', as metadata\n",
    "    metadata = {\n",
    "        \"_id\": record[\"_id\"],\n",
    "        \"category\": record[\"category\"]\n",
    "    }\n",
    "    \n",
    "    # Create the Document object\n",
    "    documents.append(Document(page_content=page_content, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c54e4b5f-e548-4ca8-9781-4ccebb4bae2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# UTIL FUNCTION\n",
    "\n",
    "index_name = \"test-index-2\"\n",
    "\n",
    "# Target the index\n",
    "dense_index = pc.Index(index_name)\n",
    "\n",
    "# Upsert the records into a namespace\n",
    "dense_index.upsert_records(\"example-namespace\", records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "efe68923-7fc8-4854-a4d4-fc6080d8015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"text-embedding-3-large\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=model_name, api_key=config['OPEN_AI_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4bfec511-4096-4056-bdc0-4f666470b837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings and upserting documents to Pinecone...\n",
      "Documents successfully added to the Pinecone index.\n"
     ]
    }
   ],
   "source": [
    "# 3. Use PineconeVectorStore to generate embeddings and add documents\n",
    "# The .from_texts() method is a convenient way to handle the entire process.\n",
    "# It embeds the texts and upserts them to the specified index.\n",
    "print(\"Generating embeddings and upserting documents to Pinecone...\")\n",
    "\n",
    "index_name = \"test-index-3\"\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "vectorstore.add_documents(documents)\n",
    "print(\"Documents successfully added to the Pinecone index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d08e56-0601-401c-9096-3558110f29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the upserted vectors to be indexed\n",
    "import time\n",
    "time.sleep(10)\n",
    "\n",
    "# View stats for the index\n",
    "stats = dense_index.describe_index_stats()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f133b30f-b020-4168-a498-e06047e9cb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the query\n",
    "query = \"Famous historical structures and monuments\"\n",
    "\n",
    "# Search the dense index\n",
    "results = dense_index.search(\n",
    "    namespace=\"__default__\",\n",
    "    query={\n",
    "        \"top_k\": 10,\n",
    "        \"inputs\": {\n",
    "            'text': query\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "for hit in results['result']['hits']:\n",
    "        print(f\"id: {hit['_id']:<5} | score: {round(hit['_score'], 2):<5} | category: {hit['fields']['category']:<10} | text: {hit['fields']['chunk_text']:<50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56eac446-a84f-453b-bc5b-7d282a93e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: rec1, score: 0.11, text: The Eiffel Tower was completed in 1889 and stands in Paris, France., category: history\n",
      "id: rec38, score: 0.06, text: The Taj Mahal is a mausoleum built by Emperor Shah Jahan., category: history\n",
      "id: rec7, score: 0.06, text: The Great Wall of China was built to protect against invasions., category: history\n",
      "id: rec21, score: 0.02, text: The Statue of Liberty was a gift from France to the United States., category: history\n",
      "id: rec17, score: 0.02, text: The Pyramids of Giza are among the Seven Wonders of the Ancient World., category: history\n",
      "id: rec26, score: 0.01, text: Rome was once the center of a vast empire., category: history\n",
      "id: rec15, score: 0.01, text: Leonardo da Vinci painted the Mona Lisa., category: art\n",
      "id: rec5, score: 0.0, text: Shakespeare wrote many famous plays, including Hamlet and Macbeth., category: literature\n",
      "id: rec47, score: 0.0, text: The Industrial Revolution transformed manufacturing and transportation., category: history\n",
      "id: rec50, score: 0.0, text: Renewable energy sources include wind, solar, and hydroelectric power., category: energy\n"
     ]
    }
   ],
   "source": [
    "# Search the dense index and rerank results\n",
    "reranked_results = dense_index.search(\n",
    "    namespace=\"example-namespace\",\n",
    "    query={\n",
    "        \"top_k\": 10,\n",
    "        \"inputs\": {\n",
    "            'text': query\n",
    "        }\n",
    "    },\n",
    "    rerank={\n",
    "        \"model\": \"bge-reranker-v2-m3\",\n",
    "        \"top_n\": 10,\n",
    "        \"rank_fields\": [\"chunk_text\"]\n",
    "    }   \n",
    ")\n",
    "\n",
    "# Print the reranked results\n",
    "for hit in reranked_results['result']['hits']:\n",
    "    print(f\"id: {hit['_id']}, score: {round(hit['_score'], 2)}, text: {hit['fields']['chunk_text']}, category: {hit['fields']['category']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b76903-b6af-489a-992e-502c72fe1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain x Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccf627b3-908b-4fed-9202-11f2af6c7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings  \n",
    "\n",
    "model_name = 'text-embedding-3-large'  \n",
    "embeddings = OpenAIEmbeddings(  \n",
    "    model=model_name,  \n",
    "    openai_api_key=config[\"OPEN_AI_KEY\"]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f8400f3-9911-488c-a0b4-06ec44cc720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT USE THIS\n",
    "\n",
    "from langchain_pinecone import PineconeEmbeddings\n",
    "\n",
    "model_name = 'llama-text-embed-v2'  \n",
    "embeddings = PineconeEmbeddings(  \n",
    "    model=model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9634c6d0-d28f-4667-92b1-df6ceee72267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore  \n",
    "\n",
    "vectorstore = PineconeVectorStore(index_name=\"test-index-2\", embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02296d1c-a523-4c01-9891-634f4944b9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d1e357ff-910f-4b01-acf9-a715c5a8bb0c', metadata={'_id': 'rec52', 'category': 'business'}, page_content='Palantir is a software company specializing in data analytics and integration platforms, primarily serving government and commercial clients. Its technology, including the platforms Gotham and Foundry, helps organizations analyze and integrate data from disparate sources to improve decision-making.'),\n",
       " Document(id='f1fff4ad-dd6b-4c29-b594-2afe747c995e', metadata={'_id': 'rec26', 'category': 'history'}, page_content='Rome was once the center of a vast empire.'),\n",
       " Document(id='4cc80cc2-7f93-442c-bae2-0cc843231d52', metadata={'_id': 'rec40', 'category': 'geography'}, page_content='Mount Everest is the tallest mountain in the world.')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Gotham?\"  \n",
    "vectorstore.similarity_search(  \n",
    "    query,  # our search query  \n",
    "    k=3  # return 3 most relevant docs  \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3981cc2-6c71-4373-be36-0dcf2f639ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is Gotham?',\n",
       " 'result': 'Gotham is a platform developed by Palantir, a software company specializing in data analytics and integration. It is used to help organizations analyze and integrate data from various sources to improve decision-making.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI  \n",
    "from langchain.chains import RetrievalQA  \n",
    "# completion llm  \n",
    "llm = ChatOpenAI(  \n",
    "    openai_api_key=config[\"OPEN_AI_KEY\"],  \n",
    "    model_name='gpt-3.5-turbo',  \n",
    "    temperature=0.0  \n",
    ")  \n",
    "qa = RetrievalQA.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")  \n",
    "qa.invoke(query)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b5fff3-2998-46ec-a1a2-8c5df55b99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Chat using LangGraph\n",
    "\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6bede3c-a4ca-4fe8-a805-8e434e23b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"    \n",
    "    retrieved_docs = vectorstore.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "408c2cb9-de19-4eeb-af49-d40837eae46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = model.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6763c1f1-5793-48d4-a473-c9234308a757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Node `query_or_respond` already present.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m END\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprebuilt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ToolNode, tools_condition\n\u001b[0;32m----> 4\u001b[0m \u001b[43mgraph_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_or_respond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m graph_builder\u001b[38;5;241m.\u001b[39madd_node(tools)\n\u001b[1;32m      6\u001b[0m graph_builder\u001b[38;5;241m.\u001b[39madd_node(generate)\n",
      "File \u001b[0;32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/langgraph/graph/state.py:357\u001b[0m, in \u001b[0;36mStateGraph.add_node\u001b[0;34m(self, node, action, metadata, input, retry, destinations)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` already present.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;241m==\u001b[39m END \u001b[38;5;129;01mor\u001b[39;00m node \u001b[38;5;241m==\u001b[39m START:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is reserved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Node `query_or_respond` already present."
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1ee33f1-8a6f-4c28-aa89-ac74b0025540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd7613f5-c48f-4582-ae90-bff0a039e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Where is California?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_tRTaves5A1u6i1sTgSBRtlki)\n",
      " Call ID: call_tRTaves5A1u6i1sTgSBRtlki\n",
      "  Args:\n",
      "    query: California location\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Error: NameError(\"name 'vector_store' is not defined\")\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "California is a state located on the west coast of the United States. It is bordered by Oregon to the north, Nevada to the east, Arizona to the southeast, and the Pacific Ocean to the west. The capital of California is Sacramento.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Where is California?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6205fcc8-d7fd-4844-a94d-083d347a96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool use is not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87853df8-71c7-4220-92bd-4a4193fbc494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"    \n",
    "    retrieved_docs = vectorstore.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f607b6c-a788-4211-a126-db814b7001a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Source: {'_id': 'rec52', 'category': 'business'}\\nContent: Palantir is a software company specializing in data analytics and integration platforms, primarily serving government and commercial clients. Its technology, including the platforms Gotham and Foundry, helps organizations analyze and integrate data from disparate sources to improve decision-making.\\n\\nSource: {'_id': 'rec51', 'category': 'business'}\\nContent: Maka Projects is a holding company that owns multiple multi-billion dollar companies including Chedr, Gymogul and Coach Central.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve(\"What is Palantir?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb98f1a8-a096-44d0-870a-d4386f70a8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Source: {'_id': 'rec52', 'category': 'business'}\\nContent: Palantir is a software company specializing in data analytics and integration platforms, primarily serving government and commercial clients. Its technology, including the platforms Gotham and Foundry, helps organizations analyze and integrate data from disparate sources to improve decision-making.\\n\\nSource: {'_id': 'rec51', 'category': 'business'}\\nContent: Maka Projects is a holding company that owns multiple multi-billion dollar companies including Chedr, Gymogul and Coach Central.\",\n",
       " [Document(id='d1e357ff-910f-4b01-acf9-a715c5a8bb0c', metadata={'_id': 'rec52', 'category': 'business'}, page_content='Palantir is a software company specializing in data analytics and integration platforms, primarily serving government and commercial clients. Its technology, including the platforms Gotham and Foundry, helps organizations analyze and integrate data from disparate sources to improve decision-making.'),\n",
       "  Document(id='d304f40d-2563-4ed3-9d75-0f5ee6bccc1e', metadata={'_id': 'rec51', 'category': 'business'}, page_content='Maka Projects is a holding company that owns multiple multi-billion dollar companies including Chedr, Gymogul and Coach Central.')])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve(\"What is Palantir?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "393e8f40-d694-42d4-a5da-a5b3dfee5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LangGraph docs\n",
    "\n",
    "# https://langchain-ai.github.io/langgraph/agents/agents/#3-configure-an-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9f28e02-44cc-45fd-a5a8-a161d7e8a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Chat model\n",
    "model = init_chat_model(\"gpt-4.1-mini\", model_provider=\"openai\", api_key=config[\"OPEN_AI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3ead6ed-c165-4c59-9ab3-edc5ad6967e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Tool\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"    \n",
    "    retrieved_docs = vectorstore.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "17e62cfc-fe0e-412c-a21a-84b042621070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Run agent\n",
    "\n",
    "# class AgentResponse(BaseModel):\n",
    "#     agent_response_last: str\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,  \n",
    "    tools=[retrieve],  \n",
    "    prompt=\"You are a helpful assistant\")\n",
    "    # response_format=AgentResponse)\n",
    "\n",
    "# Run the agent\n",
    "# agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"What is Maka Projects?\"}]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e4eb2941-f037-4417-abad-9c1264075f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Use the tool to answer the question - does honey spoil?\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cdb18f7b-6669-4bcc-bc38-f11203e05f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Use the tool to answer the question - does honey spoil?', additional_kwargs={}, response_metadata={}, id='ea7084a5-f55a-483b-bd71-1f65ceeffa71'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8ckYfMnGoWMXg5LWjFCqHvTk', 'function': {'arguments': '{\"query\":\"Does honey spoil?\"}', 'name': 'retrieve'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 61, 'total_tokens': 77, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CTDVQK1bc7MVvC0qpzDctsDI4x93B', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c0e5b378-99f5-43f5-9651-eec675b4a882-0', tool_calls=[{'name': 'retrieve', 'args': {'query': 'Does honey spoil?'}, 'id': 'call_8ckYfMnGoWMXg5LWjFCqHvTk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 16, 'total_tokens': 77, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=\"Source: {'_id': 'rec8', 'category': 'food science'}\\nContent: Honey never spoils due to its low moisture content and acidity.\\n\\nSource: {'_id': 'rec35', 'category': 'food science'}\\nContent: Ice cream melts when exposed to heat.\", name='retrieve', id='c9f3358f-5135-477b-8a73-0c3f738fc4aa', tool_call_id='call_8ckYfMnGoWMXg5LWjFCqHvTk', artifact=[Document(id='bffd441c-961c-41b9-89a7-0e7eec869dc2', metadata={'_id': 'rec8', 'category': 'food science'}, page_content='Honey never spoils due to its low moisture content and acidity.'), Document(id='d8f09d72-d807-4d86-bb09-3e4bb4e672dd', metadata={'_id': 'rec35', 'category': 'food science'}, page_content='Ice cream melts when exposed to heat.')]),\n",
       " AIMessage(content='Honey does not spoil due to its low moisture content and acidity, which prevent the growth of bacteria and other microorganisms.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 143, 'total_tokens': 167, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CTDVRleslcwjgAbS9xNonfOy7Zex2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--81873a10-e558-4eee-9e37-bef36c9f14d6-0', usage_metadata={'input_tokens': 143, 'output_tokens': 24, 'total_tokens': 167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f3171ebe-89e2-4f7f-9a22-8dffdcd40fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.utils import get_buffer_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "63494cdd-f658-4ceb-b31b-9c44713f9b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI: Honey does not spoil due to its low moisture content and acidity, which prevent the growth of bacteria and other microorganisms.'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_buffer_string(response['messages'][-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8acf583d-5bbd-401e-9caa-e80076b8bfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Source: {'_id': 'rec8', 'category': 'food science'}\\nContent: Honey never spoils due to its low moisture content and acidity.\\n\\nSource: {'_id': 'rec35', 'category': 'food science'}\\nContent: Ice cream melts when exposed to heat.\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve.invoke(\"Does honey spoil?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "98a0d5a3-f6b9-4b2b-9faa-74c302bc9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone - Debug\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))\n",
    "\n",
    "# To get the unique host for an index, \n",
    "# see https://docs.pinecone.io/guides/manage-data/target-an-index\n",
    "index = pc.Index(host=\"https://test-index-2-kuv1rfi.svc.aped-4627-b74a.pinecone.io\")\n",
    "\n",
    "results = index.search(\n",
    "    namespace=\"__default__\", \n",
    "    query={\n",
    "        \"inputs\": {\"text\": \"Disease prevention\"}, \n",
    "        \"top_k\": 2\n",
    "    })\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4f973-16a5-4998-960d-8159677c470b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
