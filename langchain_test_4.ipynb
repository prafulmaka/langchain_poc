{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c7938c-e37e-42c8-9ffc-010fc3e89437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T03:12:39.951983Z",
     "start_time": "2025-10-27T03:12:39.950161Z"
    }
   },
   "outputs": [],
   "source": [
    "# ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325d8fe4-5019-4ecb-84c7-a9cc64798ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:20:57.906020Z",
     "start_time": "2025-10-25T06:20:57.904171Z"
    }
   },
   "outputs": [],
   "source": [
    "# %env PINECONE_API_KEY=\n",
    "\n",
    "# %env PINECONE_API_KEY\n",
    "\n",
    "# %env OPENAI_API_KEY=\n",
    "# %env OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "903c7116-a64a-4cdd-bc25-7b53bfb8e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30a0d756-734e-407f-8504-16972b757c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "\n",
    "client = OpenAI(api_key=config[\"OPEN_AI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fb9a8ff-2109-4730-a110-0098fdacc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1-mini\", model_provider=\"openai\", api_key=config[\"OPEN_AI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfcd01d5-84f1-418b-bc93-8f5c54aef8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Bob! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CcFC676hDpdkyEAbqR95j3HhbcL0g', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--c713d3d0-7c64-47e5-8461-5cfe065fbdc7-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7391a05-be01-43b8-973d-40cfb9e2b397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have access to your name based on this conversation. Could you please tell me your name?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 11, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CW4lFKDA73zKirMxaSHYMgAN81sQz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f93cdb0e-397c-4724-9b28-676b657fca11-0', usage_metadata={'input_tokens': 11, 'output_tokens': 20, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What's my name?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10074069-5db1-4754-b6ce-a9690c545500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have access to your personal information unless you share it with me. What would you like me to call you?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 11, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'finish_reason': 'stop', 'logprobs': None}, id='run--a5225aa9-f01e-4204-9dba-06ef98520ed6-0', usage_metadata={'input_tokens': 11, 'output_tokens': 24, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d44587a-5e37-4f45-ba88-3bd4b96b6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a SIMPLE example of how we can store chat history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a8046c3-136f-4878-8f77-846966fc73e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Bob! I can analyze and interpret images you share with me, including individual frames extracted from a video. However, I don't have the capability to process video files directly or handle continuous video streams. If you extract specific frames from your video and upload them as images, I can certainly help analyze those! Let me know how you'd like to proceed.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 26, 'total_tokens': 96, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'finish_reason': 'stop', 'logprobs': None}, id='run--717fb43c-f755-4b28-a423-7874a5310d35-0', usage_metadata={'input_tokens': 26, 'output_tokens': 70, 'total_tokens': 96, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "        # AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"Are you able to process image frames from a video?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c8f046b-9461-4b98-95e0-7764e6dba6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how we can process images and use in LangChain messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aea7c79-7adb-4358-91b2-386827197708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, seconds_per_frame=2):\n",
    "    base64Frames = []\n",
    "    base_video_path, _ = os.path.splitext(video_path)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frames_to_skip = int(fps * seconds_per_frame)\n",
    "    curr_frame=0\n",
    "\n",
    "    # Loop through the video and extract frames at specified sampling rate\n",
    "    while curr_frame < total_frames - 1:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "        curr_frame += frames_to_skip\n",
    "    video.release()\n",
    "\n",
    "    print(f\"Extracted {len(base64Frames)} frames\")\n",
    "    return base64Frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab9fd82-a75f-4ef3-aca6-1594dd67796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 21 frames\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import base64\n",
    "video_path = \"pushup.MOV\"\n",
    "base64Frames = process_video(video_path, seconds_per_frame=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "526d065a-470d-4187-aad3-aabc58c4a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are generating a video summary. Please provide a summary of the video. Respond in Markdown.\"),\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"Please analyze the frames from this video and tell me what is happening.\"},\n",
    "            *[\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{frame}\"},\n",
    "                }\n",
    "                for frame in base64Frames\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca7d9092-7767-4f72-b6b5-a18e8f9a08d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"These frames depict a sequence where a person performs an exercise or workout routine involving a transition from standing to a crawling-like position and then moving into a plank or push-up position. Here's what is happening step-by-step:\\n\\n1. The person starts in a standing position with knees bent.\\n2. They prepare for movement by slightly leaning forward.\\n3. They bend down further, placing their hands closer to the floor.\\n4. The person places their hands on the floor while maintaining a bent-knee position.\\n5-11. The person shifts their weight forward, moving the body into a plank position, possibly transitioning between a crouch and a push-up/plank.\\n12-14. The person appears to be in a full plank or push-up position.\\n15. The person shifts back or finishes the plank position.\\n16-17. The person moves back to a crouched position.\\n18-19. The person stands back up and faces the camera with a slight smile.\\n\\nOverall, it looks like an exercise involving dynamic movement from standing to crawling/plank and back, perhaps to build strength or practice a specific calisthenics move. The final frame showing a smile indicates the person might be wrapping up or pleased with their performance.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 246, 'prompt_tokens': 51368, 'total_tokens': 51614, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'finish_reason': 'stop', 'logprobs': None}, id='run--66531a51-dc39-418e-b4cc-b54b636bc729-0', usage_metadata={'input_tokens': 51368, 'output_tokens': 246, 'total_tokens': 51614, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f63529-6361-4c24-90c4-909d9235391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can try this approach to remove any heavy HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19483a2e-7537-453f-b19f-02e59f7d769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are generating a video summary. Please provide a summary of the video. Respond in Markdown.\"),\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"Please analyze the frames from this video and tell me what is happening.\"},\n",
    "            *[\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{frame}\"},\n",
    "                }\n",
    "                for frame in base64Frames\n",
    "            ]\n",
    "        ]\n",
    "    ),\n",
    "    HumanMessage(content=\"My name is Allison. What is your name?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31ed428e-fa0e-4dcf-a87b-26cd0ba4b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the heavy image message\n",
    "for msg in messages:\n",
    "    if isinstance(msg.content, list):\n",
    "        messages.remove(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a08ea835-1afb-4a1a-a434-7b1616f6d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone POC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99558c22-8778-48fd-b199-38f8a1ddd5f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pinecone POC\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=config[\"PINECONE_API_KEY\"])\n",
    "\n",
    "# pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2960001e-8e59-4596-b598-2ed23e89f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9eaa105-943a-42d5-a916-2b3b2317183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "\n",
    "index_name = \"test-index-3\"\n",
    "openai_embedding_dimension = 3072\n",
    "\n",
    "\n",
    "# Two seperate approaches to creating an index on Pinecone\n",
    "\n",
    "# if not pc.has_index(index_name):\n",
    "#     pc.create_index_for_model(\n",
    "#         name=index_name,\n",
    "#         cloud=\"aws\",\n",
    "#         region=\"us-east-1\",\n",
    "#         embed={\n",
    "#             \"model\":\"text-embedding-3-large\",\n",
    "#             \"field_map\":{\"text\": \"chunk_text\"}\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=openai_embedding_dimension,  # Set the dimension manually\n",
    "        metric=\"cosine\",  # Specify the similarity metric\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "388c8f92-90e1-4d3c-a9bd-dc92dabc54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset\n",
    "\n",
    "records = [\n",
    "    { \"_id\": \"rec1\", \"chunk_text\": \"The Eiffel Tower was completed in 1889 and stands in Paris, France.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec2\", \"chunk_text\": \"Photosynthesis allows plants to convert sunlight into energy.\", \"category\": \"science\" },\n",
    "    { \"_id\": \"rec3\", \"chunk_text\": \"Albert Einstein developed the theory of relativity.\", \"category\": \"science\" },\n",
    "    { \"_id\": \"rec4\", \"chunk_text\": \"The mitochondrion is often called the powerhouse of the cell.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec5\", \"chunk_text\": \"Shakespeare wrote many famous plays, including Hamlet and Macbeth.\", \"category\": \"literature\" },\n",
    "    { \"_id\": \"rec6\", \"chunk_text\": \"Water boils at 100Â°C under standard atmospheric pressure.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec7\", \"chunk_text\": \"The Great Wall of China was built to protect against invasions.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec8\", \"chunk_text\": \"Honey never spoils due to its low moisture content and acidity.\", \"category\": \"food science\" },\n",
    "    { \"_id\": \"rec9\", \"chunk_text\": \"The speed of light in a vacuum is approximately 299,792 km/s.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec10\", \"chunk_text\": \"Newton's laws describe the motion of objects.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec11\", \"chunk_text\": \"The human brain has approximately 86 billion neurons.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec12\", \"chunk_text\": \"The Amazon Rainforest is one of the most biodiverse places on Earth.\", \"category\": \"geography\" },\n",
    "    { \"_id\": \"rec13\", \"chunk_text\": \"Black holes have gravitational fields so strong that not even light can escape.\", \"category\": \"astronomy\" },\n",
    "    { \"_id\": \"rec14\", \"chunk_text\": \"The periodic table organizes elements based on their atomic number.\", \"category\": \"chemistry\" },\n",
    "    { \"_id\": \"rec15\", \"chunk_text\": \"Leonardo da Vinci painted the Mona Lisa.\", \"category\": \"art\" },\n",
    "    { \"_id\": \"rec16\", \"chunk_text\": \"The internet revolutionized communication and information sharing.\", \"category\": \"technology\" },\n",
    "    { \"_id\": \"rec17\", \"chunk_text\": \"The Pyramids of Giza are among the Seven Wonders of the Ancient World.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec18\", \"chunk_text\": \"Dogs have an incredible sense of smell, much stronger than humans.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec19\", \"chunk_text\": \"The Pacific Ocean is the largest and deepest ocean on Earth.\", \"category\": \"geography\" },\n",
    "    { \"_id\": \"rec20\", \"chunk_text\": \"Chess is a strategic game that originated in India.\", \"category\": \"games\" },\n",
    "    { \"_id\": \"rec21\", \"chunk_text\": \"The Statue of Liberty was a gift from France to the United States.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec22\", \"chunk_text\": \"Coffee contains caffeine, a natural stimulant.\", \"category\": \"food science\" },\n",
    "    { \"_id\": \"rec23\", \"chunk_text\": \"Thomas Edison invented the practical electric light bulb.\", \"category\": \"inventions\" },\n",
    "    { \"_id\": \"rec24\", \"chunk_text\": \"The moon influences ocean tides due to gravitational pull.\", \"category\": \"astronomy\" },\n",
    "    { \"_id\": \"rec25\", \"chunk_text\": \"DNA carries genetic information for all living organisms.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec26\", \"chunk_text\": \"Rome was once the center of a vast empire.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec27\", \"chunk_text\": \"The Wright brothers pioneered human flight in 1903.\", \"category\": \"inventions\" },\n",
    "    { \"_id\": \"rec28\", \"chunk_text\": \"Bananas are a good source of potassium.\", \"category\": \"nutrition\" },\n",
    "    { \"_id\": \"rec29\", \"chunk_text\": \"The stock market fluctuates based on supply and demand.\", \"category\": \"economics\" },\n",
    "    { \"_id\": \"rec30\", \"chunk_text\": \"A compass needle points toward the magnetic north pole.\", \"category\": \"navigation\" },\n",
    "    { \"_id\": \"rec31\", \"chunk_text\": \"The universe is expanding, according to the Big Bang theory.\", \"category\": \"astronomy\" },\n",
    "    { \"_id\": \"rec32\", \"chunk_text\": \"Elephants have excellent memory and strong social bonds.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec33\", \"chunk_text\": \"The violin is a string instrument commonly used in orchestras.\", \"category\": \"music\" },\n",
    "    { \"_id\": \"rec34\", \"chunk_text\": \"The heart pumps blood throughout the human body.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec35\", \"chunk_text\": \"Ice cream melts when exposed to heat.\", \"category\": \"food science\" },\n",
    "    { \"_id\": \"rec36\", \"chunk_text\": \"Solar panels convert sunlight into electricity.\", \"category\": \"technology\" },\n",
    "    { \"_id\": \"rec37\", \"chunk_text\": \"The French Revolution began in 1789.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec38\", \"chunk_text\": \"The Taj Mahal is a mausoleum built by Emperor Shah Jahan.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec39\", \"chunk_text\": \"Rainbows are caused by light refracting through water droplets.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec40\", \"chunk_text\": \"Mount Everest is the tallest mountain in the world.\", \"category\": \"geography\" },\n",
    "    { \"_id\": \"rec41\", \"chunk_text\": \"Octopuses are highly intelligent marine creatures.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec42\", \"chunk_text\": \"The speed of sound is around 343 meters per second in air.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec43\", \"chunk_text\": \"Gravity keeps planets in orbit around the sun.\", \"category\": \"astronomy\" },\n",
    "    { \"_id\": \"rec44\", \"chunk_text\": \"The Mediterranean diet is considered one of the healthiest in the world.\", \"category\": \"nutrition\" },\n",
    "    { \"_id\": \"rec45\", \"chunk_text\": \"A haiku is a traditional Japanese poem with a 5-7-5 syllable structure.\", \"category\": \"literature\" },\n",
    "    { \"_id\": \"rec46\", \"chunk_text\": \"The human body is made up of about 60% water.\", \"category\": \"biology\" },\n",
    "    { \"_id\": \"rec47\", \"chunk_text\": \"The Industrial Revolution transformed manufacturing and transportation.\", \"category\": \"history\" },\n",
    "    { \"_id\": \"rec48\", \"chunk_text\": \"Vincent van Gogh painted Starry Night.\", \"category\": \"art\" },\n",
    "    { \"_id\": \"rec49\", \"chunk_text\": \"Airplanes fly due to the principles of lift and aerodynamics.\", \"category\": \"physics\" },\n",
    "    { \"_id\": \"rec50\", \"chunk_text\": \"Renewable energy sources include wind, solar, and hydroelectric power.\", \"category\": \"energy\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ae327221-45c0-48a1-9eaa-49f043286d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset\n",
    "\n",
    "records = [\n",
    "    { \"_id\": \"rec51\", \"chunk_text\": \"Maka Projects is a holding company that owns multiple multi-billion dollar companies including Chedr, Gymogul and Coach Central.\", \"category\": \"business\" },\n",
    "    { \"_id\": \"rec52\", \"chunk_text\": \"Palantir is a software company specializing in data analytics and integration platforms, primarily serving government and commercial clients. Its technology, including the platforms Gotham and Foundry, helps organizations analyze and integrate data from disparate sources to improve decision-making.\", \"category\": \"business\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8554adde-a8ac-4732-a7dd-cdac113741db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format records\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "documents = []\n",
    "for record in records:\n",
    "    # Use 'chunk_text' as the page_content for embedding\n",
    "    page_content = record[\"chunk_text\"]\n",
    "    \n",
    "    # Store all other fields, including the original '_id', as metadata\n",
    "    metadata = {\n",
    "        \"_id\": record[\"_id\"],\n",
    "        \"category\": record[\"category\"]\n",
    "    }\n",
    "    \n",
    "    # Create the Document object\n",
    "    documents.append(Document(page_content=page_content, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c54e4b5f-e548-4ca8-9781-4ccebb4bae2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PineconeApiException",
     "evalue": "(400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Sat, 15 Nov 2025 18:21:58 GMT', 'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '116', 'Connection': 'keep-alive', 'x-pinecone-api-version': '2025-04', 'x-envoy-upstream-service-time': '1', 'server': 'envoy'})\nHTTP response body: {\"error\":{\"code\":\"INVALID_ARGUMENT\",\"message\":\"Integrated inference is not configured for this index\"},\"status\":400}\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPineconeApiException\u001B[39m                      Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m dense_index = pc.Index(index_name)\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Upsert the records into a namespace\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43mdense_index\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupsert_records\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtext-namespace\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecords\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/db_data/index.py:278\u001B[39m, in \u001B[36mIndex.upsert_records\u001B[39m\u001B[34m(self, namespace, records)\u001B[39m\n\u001B[32m    276\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mupsert_records\u001B[39m(\u001B[38;5;28mself\u001B[39m, namespace: \u001B[38;5;28mstr\u001B[39m, records: List[Dict]):\n\u001B[32m    277\u001B[39m     args = IndexRequestFactory.upsert_records_args(namespace=namespace, records=records)\n\u001B[32m--> \u001B[39m\u001B[32m278\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_vector_api\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupsert_records_namespace\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/openapi_support/endpoint.py:102\u001B[39m, in \u001B[36mEndpoint.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m     92\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"This method is invoked when endpoints are called\u001B[39;00m\n\u001B[32m     93\u001B[39m \u001B[33;03m    Example:\u001B[39;00m\n\u001B[32m     94\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    100\u001B[39m \n\u001B[32m    101\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m102\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcallable\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/core/openapi/db_data/api/vector_operations_api.py:606\u001B[39m, in \u001B[36mVectorOperationsApi.__init__.<locals>.__upsert_records_namespace\u001B[39m\u001B[34m(self, namespace, upsert_record, **kwargs)\u001B[39m\n\u001B[32m    604\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33mnamespace\u001B[39m\u001B[33m\"\u001B[39m] = namespace\n\u001B[32m    605\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33mupsert_record\u001B[39m\u001B[33m\"\u001B[39m] = upsert_record\n\u001B[32m--> \u001B[39m\u001B[32m606\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_with_http_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/openapi_support/endpoint.py:134\u001B[39m, in \u001B[36mEndpoint.call_with_http_info\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m    124\u001B[39m params = EndpointUtils.gather_params(\n\u001B[32m    125\u001B[39m     attribute_map=\u001B[38;5;28mself\u001B[39m.attribute_map,\n\u001B[32m    126\u001B[39m     location_map=\u001B[38;5;28mself\u001B[39m.location_map,\n\u001B[32m   (...)\u001B[39m\u001B[32m    129\u001B[39m     kwargs=kwargs,\n\u001B[32m    130\u001B[39m )\n\u001B[32m    132\u001B[39m HeaderUtil.prepare_headers(headers_map=\u001B[38;5;28mself\u001B[39m.headers_map, params=params)\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapi_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_api\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    135\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msettings\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mendpoint_path\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    136\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msettings\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhttp_method\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    137\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpath\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    138\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mquery\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m    \u001B[49m\u001B[43mheader_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mheader\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mbody\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpost_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mform\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    142\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfile\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    143\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresponse_type\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msettings\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_type\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    144\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauth_settings\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msettings\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mauth\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    145\u001B[39m \u001B[43m    \u001B[49m\u001B[43masync_req\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43masync_req\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    146\u001B[39m \u001B[43m    \u001B[49m\u001B[43masync_threadpool_executor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43masync_threadpool_executor\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    147\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_check_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m_check_return_type\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    148\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_return_http_data_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m_return_http_data_only\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    149\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_preload_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m_preload_content\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    150\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_request_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m_request_timeout\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_host\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_host\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    152\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcollection_formats\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcollection_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    153\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/openapi_support/api_client.py:306\u001B[39m, in \u001B[36mApiClient.call_api\u001B[39m\u001B[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, async_threadpool_executor, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001B[39m\n\u001B[32m    285\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.threadpool_executor.submit(\n\u001B[32m    286\u001B[39m         \u001B[38;5;28mself\u001B[39m.__call_api,\n\u001B[32m    287\u001B[39m         resource_path,\n\u001B[32m   (...)\u001B[39m\u001B[32m    302\u001B[39m         _check_type,\n\u001B[32m    303\u001B[39m     )\n\u001B[32m    305\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m async_req:\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__call_api\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresource_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    308\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    309\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpath_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    310\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheader_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpost_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresponse_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m        \u001B[49m\u001B[43mauth_settings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_return_http_data_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcollection_formats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_preload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_request_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    321\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_host\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    322\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_check_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    323\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    325\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pool.apply_async(\n\u001B[32m    326\u001B[39m     \u001B[38;5;28mself\u001B[39m.__call_api,\n\u001B[32m    327\u001B[39m     (\n\u001B[32m   (...)\u001B[39m\u001B[32m    344\u001B[39m     ),\n\u001B[32m    345\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/openapi_support/api_client.py:182\u001B[39m, in \u001B[36mApiClient.__call_api\u001B[39m\u001B[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001B[39m\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m PineconeApiException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    181\u001B[39m     e.body = e.body.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    184\u001B[39m \u001B[38;5;28mself\u001B[39m.last_response = response_data\n\u001B[32m    186\u001B[39m return_data = response_data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/openapi_support/api_client.py:170\u001B[39m, in \u001B[36mApiClient.__call_api\u001B[39m\u001B[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001B[39m\n\u001B[32m    161\u001B[39m url = build_request_url(\n\u001B[32m    162\u001B[39m     config=config,\n\u001B[32m    163\u001B[39m     processed_path_params=path_params_tuple,\n\u001B[32m    164\u001B[39m     resource_path=resource_path,\n\u001B[32m    165\u001B[39m     _host=_host,\n\u001B[32m    166\u001B[39m )\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    169\u001B[39m     \u001B[38;5;66;03m# perform request and return response\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m170\u001B[39m     response_data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    171\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    172\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    173\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprocessed_query_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    174\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    175\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpost_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprocessed_post_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    176\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_preload_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_preload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_request_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_request_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m PineconeApiException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    181\u001B[39m     e.body = e.body.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/openapi_support/api_client.py:386\u001B[39m, in \u001B[36mApiClient.request\u001B[39m\u001B[34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001B[39m\n\u001B[32m    376\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.rest_client.OPTIONS(\n\u001B[32m    377\u001B[39m         url,\n\u001B[32m    378\u001B[39m         query_params=query_params,\n\u001B[32m   (...)\u001B[39m\u001B[32m    383\u001B[39m         body=body,\n\u001B[32m    384\u001B[39m     )\n\u001B[32m    385\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m method == \u001B[33m\"\u001B[39m\u001B[33mPOST\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m386\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrest_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPOST\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpost_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpost_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_preload_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_preload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_request_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_request_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    395\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m method == \u001B[33m\"\u001B[39m\u001B[33mPUT\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    396\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.rest_client.PUT(\n\u001B[32m    397\u001B[39m         url,\n\u001B[32m    398\u001B[39m         query_params=query_params,\n\u001B[32m   (...)\u001B[39m\u001B[32m    403\u001B[39m         body=body,\n\u001B[32m    404\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/openapi_support/rest_utils.py:146\u001B[39m, in \u001B[36mRestClientInterface.POST\u001B[39m\u001B[34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001B[39m\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mPOST\u001B[39m(\n\u001B[32m    137\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    138\u001B[39m     url,\n\u001B[32m   (...)\u001B[39m\u001B[32m    144\u001B[39m     _request_timeout=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    145\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m146\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    147\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mPOST\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    148\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    149\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    150\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpost_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpost_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    152\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_preload_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_preload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    153\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_request_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_request_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    154\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    155\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/openapi_support/rest_urllib3.py:267\u001B[39m, in \u001B[36mUrllib3RestClient.request\u001B[39m\u001B[34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001B[39m\n\u001B[32m    264\u001B[39m     \u001B[38;5;66;03m# log response body\u001B[39;00m\n\u001B[32m    265\u001B[39m     logger.debug(\u001B[33m\"\u001B[39m\u001B[33mresponse body: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m, r.data)\n\u001B[32m--> \u001B[39m\u001B[32m267\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mraise_exceptions_or_return\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/pinecone/openapi_support/rest_utils.py:49\u001B[39m, in \u001B[36mraise_exceptions_or_return\u001B[39m\u001B[34m(r)\u001B[39m\n\u001B[32m     46\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[32m500\u001B[39m <= r.status <= \u001B[32m599\u001B[39m:\n\u001B[32m     47\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m ServiceException(http_resp=r)\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PineconeApiException(http_resp=r)\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "\u001B[31mPineconeApiException\u001B[39m: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Sat, 15 Nov 2025 18:21:58 GMT', 'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '116', 'Connection': 'keep-alive', 'x-pinecone-api-version': '2025-04', 'x-envoy-upstream-service-time': '1', 'server': 'envoy'})\nHTTP response body: {\"error\":{\"code\":\"INVALID_ARGUMENT\",\"message\":\"Integrated inference is not configured for this index\"},\"status\":400}\n"
     ]
    }
   ],
   "source": [
    "# UTIL FUNCTION\n",
    "\n",
    "index_name = \"test-index-3\"\n",
    "\n",
    "# Target the index\n",
    "dense_index = pc.Index(index_name)\n",
    "\n",
    "# Upsert the records into a namespace\n",
    "dense_index.upsert_records(\"text-namespace\", records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efe68923-7fc8-4854-a4d4-fc6080d8015b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAIEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m model_name = \u001B[33m\"\u001B[39m\u001B[33mtext-embedding-3-large\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m embeddings = \u001B[43mOpenAIEmbeddings\u001B[49m(model=model_name, api_key=config[\u001B[33m'\u001B[39m\u001B[33mOPEN_AI_KEY\u001B[39m\u001B[33m'\u001B[39m])\n",
      "\u001B[31mNameError\u001B[39m: name 'OpenAIEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = \"text-embedding-3-large\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=model_name, api_key=config['OPEN_AI_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4bfec511-4096-4056-bdc0-4f666470b837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings and upserting documents to Pinecone...\n",
      "Documents successfully added to the Pinecone index.\n"
     ]
    }
   ],
   "source": [
    "# 3. Use PineconeVectorStore to generate embeddings and add documents\n",
    "# The .from_texts() method is a convenient way to handle the entire process.\n",
    "# It embeds the texts and upserts them to the specified index.\n",
    "print(\"Generating embeddings and upserting documents to Pinecone...\")\n",
    "\n",
    "index_name = \"test-index-3\"\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    ")\n",
    "\n",
    "vectorstore.add_documents(documents)\n",
    "print(\"Documents successfully added to the Pinecone index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d08e56-0601-401c-9096-3558110f29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the upserted vectors to be indexed\n",
    "import time\n",
    "time.sleep(10)\n",
    "\n",
    "# View stats for the index\n",
    "stats = dense_index.describe_index_stats()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f133b30f-b020-4168-a498-e06047e9cb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the query\n",
    "query = \"Famous historical structures and monuments\"\n",
    "\n",
    "# Search the dense index\n",
    "results = dense_index.search(\n",
    "    namespace=\"__default__\",\n",
    "    query={\n",
    "        \"top_k\": 10,\n",
    "        \"inputs\": {\n",
    "            'text': query\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "for hit in results['result']['hits']:\n",
    "        print(f\"id: {hit['_id']:<5} | score: {round(hit['_score'], 2):<5} | category: {hit['fields']['category']:<10} | text: {hit['fields']['chunk_text']:<50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56eac446-a84f-453b-bc5b-7d282a93e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: rec1, score: 0.11, text: The Eiffel Tower was completed in 1889 and stands in Paris, France., category: history\n",
      "id: rec38, score: 0.06, text: The Taj Mahal is a mausoleum built by Emperor Shah Jahan., category: history\n",
      "id: rec7, score: 0.06, text: The Great Wall of China was built to protect against invasions., category: history\n",
      "id: rec21, score: 0.02, text: The Statue of Liberty was a gift from France to the United States., category: history\n",
      "id: rec17, score: 0.02, text: The Pyramids of Giza are among the Seven Wonders of the Ancient World., category: history\n",
      "id: rec26, score: 0.01, text: Rome was once the center of a vast empire., category: history\n",
      "id: rec15, score: 0.01, text: Leonardo da Vinci painted the Mona Lisa., category: art\n",
      "id: rec5, score: 0.0, text: Shakespeare wrote many famous plays, including Hamlet and Macbeth., category: literature\n",
      "id: rec47, score: 0.0, text: The Industrial Revolution transformed manufacturing and transportation., category: history\n",
      "id: rec50, score: 0.0, text: Renewable energy sources include wind, solar, and hydroelectric power., category: energy\n"
     ]
    }
   ],
   "source": [
    "# Search the dense index and rerank results\n",
    "reranked_results = dense_index.search(\n",
    "    namespace=\"example-namespace\",\n",
    "    query={\n",
    "        \"top_k\": 10,\n",
    "        \"inputs\": {\n",
    "            'text': query\n",
    "        }\n",
    "    },\n",
    "    rerank={\n",
    "        \"model\": \"bge-reranker-v2-m3\",\n",
    "        \"top_n\": 10,\n",
    "        \"rank_fields\": [\"chunk_text\"]\n",
    "    }   \n",
    ")\n",
    "\n",
    "# Print the reranked results\n",
    "for hit in reranked_results['result']['hits']:\n",
    "    print(f\"id: {hit['_id']}, score: {round(hit['_score'], 2)}, text: {hit['fields']['chunk_text']}, category: {hit['fields']['category']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b76903-b6af-489a-992e-502c72fe1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain x Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccf627b3-908b-4fed-9202-11f2af6c7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings  \n",
    "\n",
    "model_name = 'text-embedding-3-large'  \n",
    "embeddings = OpenAIEmbeddings(  \n",
    "    model=model_name,  \n",
    "    openai_api_key=config[\"OPEN_AI_KEY\"]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f8400f3-9911-488c-a0b4-06ec44cc720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT USE THIS\n",
    "\n",
    "from langchain_pinecone import PineconeEmbeddings\n",
    "\n",
    "model_name = 'llama-text-embed-v2'  \n",
    "embeddings = PineconeEmbeddings(  \n",
    "    model=model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9634c6d0-d28f-4667-92b1-df6ceee72267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore  \n",
    "\n",
    "vectorstore = PineconeVectorStore(index_name=\"test-index-3\", embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02296d1c-a523-4c01-9891-634f4944b9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='ba5eac1d-b1b3-42a2-a6cf-4803afe2fddd', metadata={'_id': 'rec52', 'category': 'business'}, page_content='Palantir is a software company specializing in data analytics and integration platforms, primarily serving government and commercial clients. Its technology, including the platforms Gotham and Foundry, helps organizations analyze and integrate data from disparate sources to improve decision-making.'),\n",
       " Document(id='74eb0873-0e26-4c2f-8909-97a37b87ab8c', metadata={'_id': 'rec26', 'category': 'history'}, page_content='Rome was once the center of a vast empire.'),\n",
       " Document(id='aeba9edb-e734-4e94-a281-cb3cc5213e34', metadata={'_id': 'rec51', 'category': 'business'}, page_content='Maka Projects is a holding company that owns multiple multi-billion dollar companies including Chedr, Gymogul and Coach Central.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Gotham?\"  \n",
    "vectorstore.similarity_search(  \n",
    "    query,  # our search query  \n",
    "    k=3  # return 3 most relevant docs  \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3981cc2-6c71-4373-be36-0dcf2f639ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is Gotham?',\n",
       " 'result': 'Gotham is a platform developed by Palantir, a software company specializing in data analytics and integration. It is used to help organizations analyze and integrate data from various sources to improve decision-making.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI  \n",
    "from langchain.chains import RetrievalQA  \n",
    "# completion llm  \n",
    "llm = ChatOpenAI(  \n",
    "    openai_api_key=config[\"OPEN_AI_KEY\"],  \n",
    "    model_name='gpt-3.5-turbo',  \n",
    "    temperature=0.0  \n",
    ")  \n",
    "qa = RetrievalQA.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")  \n",
    "qa.invoke(query)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "393e8f40-d694-42d4-a5da-a5b3dfee5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LangGraph docs\n",
    "\n",
    "# https://langchain-ai.github.io/langgraph/agents/agents/#3-configure-an-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9f28e02-44cc-45fd-a5a8-a161d7e8a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Chat model\n",
    "model = init_chat_model(\"gpt-5-mini-2025-08-07\", model_provider=\"openai\", api_key=config[\"OPEN_AI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3ead6ed-c165-4c59-9ab3-edc5ad6967e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Tool\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"    \n",
    "    retrieved_docs = vectorstore.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17e62cfc-fe0e-412c-a21a-84b042621070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Run agent\n",
    "\n",
    "# class AgentResponse(BaseModel):\n",
    "#     agent_response_last: str\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,  \n",
    "    tools=[retrieve],  \n",
    "    prompt=\"You are a helpful assistant\")\n",
    "    # response_format=AgentResponse)\n",
    "\n",
    "# Run the agent\n",
    "# agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"What is Maka Projects?\"}]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4eb2941-f037-4417-abad-9c1264075f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Use the tool to answer the question - what is maka projects?\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdb18f7b-6669-4bcc-bc38-f11203e05f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Use the tool to answer the question - what is maka projects?', additional_kwargs={}, response_metadata={}, id='16953f17-6fed-4d35-bb43-82d5fe8c84c7'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HjmIzkTzZQk3Gjwd8k1Pk3AD', 'function': {'arguments': '{\"query\":\"Maka Projects\"}', 'name': 'retrieve'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 152, 'prompt_tokens': 146, 'total_tokens': 298, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CVSrX1BaBMrN64gU7WralYgEIEgak', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--72c5d6a7-c83d-4e79-8cae-fe500c5dbc66-0', tool_calls=[{'name': 'retrieve', 'args': {'query': 'Maka Projects'}, 'id': 'call_HjmIzkTzZQk3Gjwd8k1Pk3AD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 146, 'output_tokens': 152, 'total_tokens': 298, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}}),\n",
       " ToolMessage(content='Error: PineconeApiException()\\n Please fix your mistakes.', name='retrieve', id='7e860245-f448-4a47-80b2-66b3e9b70270', tool_call_id='call_HjmIzkTzZQk3Gjwd8k1Pk3AD', status='error'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_jfaqVOxQNS3BtwHzD1rqL9Wl', 'function': {'arguments': '{\"query\":\"Maka Projects company Maka Projects \\'Maka Projects\\' \\'Maka Projects what is\\'\"}', 'name': 'retrieve'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 186, 'total_tokens': 219, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CVSrcMpmCvSE4ubrEpEK15Lrrj7nq', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8309b0fb-7d97-40e4-950e-35a9e4a5176c-0', tool_calls=[{'name': 'retrieve', 'args': {'query': \"Maka Projects company Maka Projects 'Maka Projects' 'Maka Projects what is'\"}, 'id': 'call_jfaqVOxQNS3BtwHzD1rqL9Wl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 186, 'output_tokens': 33, 'total_tokens': 219, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Error: PineconeApiException()\\n Please fix your mistakes.', name='retrieve', id='423f8423-97f3-4f8b-b186-bd9577f9d62a', tool_call_id='call_jfaqVOxQNS3BtwHzD1rqL9Wl', status='error'),\n",
       " AIMessage(content='I tried to use the tool you requested but the retrieval call failed with a PineconeApiException (the tool returned an error). I can:\\n\\n- Retry the tool now (I can try another retrieval call).\\n- Continue without the tool and answer based on whatever context you can give (e.g., a location, industry, or a link).\\n- If you want me to search the web, confirm and Iâll attempt a web lookup or try the tool again.\\n\\nWhich would you prefer? If you want an immediate answer, please paste a link or any extra context about âMaka Projectsâ (country, industry, or where you heard the name).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 588, 'prompt_tokens': 241, 'total_tokens': 829, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CVSreUUzY1ej9YI2w7jpPBZDqOF8u', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--36540e2c-3c98-4c56-87fe-f4a9bcbc74c3-0', usage_metadata={'input_tokens': 241, 'output_tokens': 588, 'total_tokens': 829, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3171ebe-89e2-4f7f-9a22-8dffdcd40fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.utils import get_buffer_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63494cdd-f658-4ceb-b31b-9c44713f9b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI: I tried to use the tool you requested but the retrieval call failed with a PineconeApiException (the tool returned an error). I can:\\n\\n- Retry the tool now (I can try another retrieval call).\\n- Continue without the tool and answer based on whatever context you can give (e.g., a location, industry, or a link).\\n- If you want me to search the web, confirm and Iâll attempt a web lookup or try the tool again.\\n\\nWhich would you prefer? If you want an immediate answer, please paste a link or any extra context about âMaka Projectsâ (country, industry, or where you heard the name).'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_buffer_string(response['messages'][-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c544a2-e5f6-4071-9f61-debb4597cc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: Maka Projects?\n",
      "Embedding vector (first 50 dimensions): [-0.0006819737609475851, -0.011270695365965366, -0.02970528043806553, -0.011546937748789787, -0.01211783941835165, 0.023443782702088356, -0.015395916998386383, 0.013149145059287548, 0.0043991622515022755, 0.022946545854210854, 0.04964999109506607, -0.04305700212717056, -0.00476057967171073, -0.004376142285764217, 0.018499042838811874, 0.02316754125058651, -0.029613200575113297, 0.018259631469845772, -0.011906052939593792, -0.02219148352742195, -0.024475088343024254, -0.04419880732893944, -0.058452919125556946, -0.010073644109070301, 0.007453944534063339, -0.006270705722272396, -0.013139937072992325, -0.011436440981924534, -0.02127067558467388, 0.005464998073875904, -0.0007907442632131279, 0.014788183383643627, 0.013250433839857578, 0.05034980550408363, -0.00921268854290247, 0.002267490839585662, 0.04357265681028366, 0.007845288142561913, 0.0398157574236393, -0.02025778591632843, 0.004926325287669897, -0.032430872321128845, -0.015828697010874748, 0.036464013159275055, -0.004258739296346903, -0.002983419457450509, -0.02460400201380253, -0.000779234163928777, -0.006629820913076401, -0.012578243389725685]...\n",
      "Vector dimension: 3072\n"
     ]
    }
   ],
   "source": [
    "# Function to embed text > to feed to Pinecone index.query\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Generates a vector embedding for the given text using OpenAI's model.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \") # Best practice is to replace newlines\n",
    "    response = client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    # The embedding is in the 'data' array of the response\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"Maka Projects?\"\n",
    "embedding_vector = get_embedding(sentence)\n",
    "\n",
    "print(f\"Original sentence: {sentence}\")\n",
    "print(f\"Embedding vector (first 50 dimensions): {embedding_vector[:50]}...\")\n",
    "print(f\"Vector dimension: {len(embedding_vector)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a0d5a3-f6b9-4b2b-9faa-74c302bc9c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramaka/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'aeba9edb-e734-4e94-a281-cb3cc5213e34',\n",
       "              'metadata': {'_id': 'rec51',\n",
       "                           'category': 'business',\n",
       "                           'text': 'Maka Projects is a holding company that '\n",
       "                                   'owns multiple multi-billion dollar '\n",
       "                                   'companies including Chedr, Gymogul and '\n",
       "                                   'Coach Central.'},\n",
       "              'score': 0.624095917,\n",
       "              'values': []},\n",
       "             {'id': 'ba5eac1d-b1b3-42a2-a6cf-4803afe2fddd',\n",
       "              'metadata': {'_id': 'rec52',\n",
       "                           'category': 'business',\n",
       "                           'text': 'Palantir is a software company '\n",
       "                                   'specializing in data analytics and '\n",
       "                                   'integration platforms, primarily serving '\n",
       "                                   'government and commercial clients. Its '\n",
       "                                   'technology, including the platforms Gotham '\n",
       "                                   'and Foundry, helps organizations analyze '\n",
       "                                   'and integrate data from disparate sources '\n",
       "                                   'to improve decision-making.'},\n",
       "              'score': 0.195915192,\n",
       "              'values': []},\n",
       "             {'id': 'c4ece4b8-0712-4177-8f7b-821a96fe77be',\n",
       "              'metadata': {'_id': 'rec4',\n",
       "                           'category': 'biology',\n",
       "                           'text': 'The mitochondrion is often called the '\n",
       "                                   'powerhouse of the cell.'},\n",
       "              'score': 0.107151017,\n",
       "              'values': []}],\n",
       " 'namespace': '__default__',\n",
       " 'usage': {'read_units': 1}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pinecone - Debug\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))\n",
    "\n",
    "# To get the unique host for an index, \n",
    "# see https://docs.pinecone.io/guides/manage-data/target-an-index\n",
    "index = pc.Index(host=\"https://test-index-3.pinecone.io\")\n",
    "\n",
    "# Index.search will not work with this index\n",
    "# Integrated inference is not configured for this index\n",
    "\n",
    "# results = index.query(\n",
    "#     namespace=\"__default__\", \n",
    "#     query={\n",
    "#         \"inputs\": {\"text\": \"Disease prevention\"}\n",
    "#     },\n",
    "#     top_k=3,\n",
    "#     include_metadata=True,\n",
    "#     include_values=False\n",
    "# )\n",
    "\n",
    "# print(results)\n",
    "\n",
    "# Pinecone index.query\n",
    "\n",
    "index.query(\n",
    "    namespace=\"__default__\",\n",
    "    vector=embedding_vector,\n",
    "    top_k=3,\n",
    "    include_metadata=True,\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "64ec71c4ce655ed7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
