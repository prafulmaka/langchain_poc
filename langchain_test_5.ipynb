{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e2f219e-0007-4d81-92dc-797af830a4f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T21:06:11.405051Z",
     "start_time": "2025-11-18T21:06:11.403193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing LangChain v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebaa878-0c13-4be1-a5c5-c0274979ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.langchain.com/oss/python/langchain/rag"
   ]
  },
  {
   "cell_type": "code",
   "id": "0a5b401c-ca6f-4e63-9a7a-dbe88dadf01b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:10:37.459636Z",
     "start_time": "2025-12-02T09:10:37.163443Z"
    }
   },
   "source": [
    "from dotenv import dotenv_values\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "client = OpenAI(api_key=config[\"OPEN_AI_KEY\"])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096f0263-5362-49cc-b76e-130d65b87c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings  \n",
    "\n",
    "model_name = 'text-embedding-3-large'  \n",
    "embeddings = OpenAIEmbeddings(  \n",
    "    model=model_name,  \n",
    "    openai_api_key=config[\"OPEN_AI_KEY\"]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3fceeb7-b5b5-4471-855b-64933d8864c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:10:41.185130Z",
     "start_time": "2025-12-02T09:10:41.110684Z"
    }
   },
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=config[\"PINECONE_API_KEY\"])\n",
    "\n",
    "# pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0d78b9-ab97-41c8-9116-1428f03700bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: What does the knowledge source say about the speed of light?\n",
      "Embedding vector (first 50 dimensions): [0.0032393874134868383, -0.015876037999987602, -0.0058910236693918705, 0.02307767979800701, -0.02295607700943947, -0.019956517964601517, 0.04064266011118889, 0.03507591038942337, 0.020929347723722458, 0.028860611841082573, 0.011248341761529446, 0.057883359491825104, 0.024172112345695496, -0.005850489251315594, -0.01335613988339901, 0.0789613351225853, 0.013254803605377674, 0.00015327133587561548, -0.016078710556030273, 0.02306416817009449, -0.019172849133610725, -0.009437798522412777, 0.018713457509875298, -0.020726675167679787, -0.02545570768415928, 0.0070732817985117435, 0.009768830612301826, 0.003894696244969964, -0.002193933352828026, 0.009755318984389305, 0.03245467692613602, -0.0036413553170859814, -0.005739019252359867, -0.015578784979879856, 0.0014896453358232975, -0.05180317535996437, -0.02125362493097782, -0.022266987711191177, -0.02749594673514366, -0.00792450737208128, 0.017416352406144142, 0.012369798496365547, -0.012667052447795868, -0.02807694301009178, -0.03372475877404213, 0.0014364436501637101, -0.02229401096701622, -0.016592148691415787, 0.04647963494062424, -0.04466909170150757]...\n",
      "Vector dimension: 3072\n"
     ]
    }
   ],
   "source": [
    "# Function to embed text > to feed to Pinecone index.query\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Generates a vector embedding for the given text using OpenAI's model.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \") # Best practice is to replace newlines\n",
    "    response = client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    # The embedding is in the 'data' array of the response\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"What does the knowledge source say about the speed of light?\"\n",
    "embedding_vector = get_embedding(sentence)\n",
    "\n",
    "print(f\"Original sentence: {sentence}\")\n",
    "print(f\"Embedding vector (first 50 dimensions): {embedding_vector[:50]}...\")\n",
    "print(f\"Vector dimension: {len(embedding_vector)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cae69c0-9c34-4604-a30e-4842996a0fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramaka/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Pinecone - Debug\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))\n",
    "\n",
    "# To get the unique host for an index, \n",
    "# see https://docs.pinecone.io/guides/manage-data/target-an-index\n",
    "index = pc.Index(host=\"https://test-index-3-kuv1rfi.svc.aped-4627-b74a.pinecone.io\")\n",
    "\n",
    "# Index.search will not work with this index\n",
    "# Integrated inference is not configured for this index\n",
    "\n",
    "# results = index.query(\n",
    "#     namespace=\"__default__\", \n",
    "#     query={\n",
    "#         \"inputs\": {\"text\": \"Disease prevention\"}\n",
    "#     },\n",
    "#     top_k=3,\n",
    "#     include_metadata=True,\n",
    "#     include_values=False\n",
    "# )\n",
    "\n",
    "# print(results)\n",
    "\n",
    "# Pinecone index.query\n",
    "\n",
    "response = index.query(\n",
    "    namespace=\"__default__\",\n",
    "    vector=embedding_vector, \n",
    "    top_k=3,\n",
    "    include_metadata=True,\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c06515-6dce-4df8-9e6e-b556b2a79194",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = response['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26eb4c24-776c-45b2-9196-efa9af9120ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '4ba7ae68-92db-42e2-b5c7-c18141c84da3',\n",
       "   'score': 0.578466415,\n",
       "   'values': [],\n",
       "   'metadata': {'_id': 'rec9',\n",
       "    'category': 'physics',\n",
       "    'text': 'The speed of light in a vacuum is approximately 299,792 km/s.'}},\n",
       "  {'id': '01cf5e66-b57b-42c3-a46e-ef66cc490e86',\n",
       "   'score': 0.348688155,\n",
       "   'values': [],\n",
       "   'metadata': {'_id': 'rec42',\n",
       "    'category': 'physics',\n",
       "    'text': 'The speed of sound is around 343 meters per second in air.'}},\n",
       "  {'id': '45277ff9-a7b7-43e3-a480-6db9d2978300',\n",
       "   'score': 0.290880233,\n",
       "   'values': [],\n",
       "   'metadata': {'_id': 'rec31',\n",
       "    'category': 'astronomy',\n",
       "    'text': 'The universe is expanding, according to the Big Bang theory.'}}],\n",
       " 'namespace': '__default__',\n",
       " 'usage': {'read_units': 1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "219deb35-85c9-47d1-998a-2022055f21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.verbose = False\n",
    "# langchain.debug = False\n",
    "# langchain.llm_cache = False\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1-mini\", model_provider=\"openai\", api_key=config[\"OPEN_AI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2e6dc7-cf0b-4025-b4ce-b5e814d216de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc491a58-080b-4b91-ab13-fd1ff04600d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2\n",
    "\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    \n",
    "    # Get embedding for message\n",
    "    embedding = get_embedding(last_query)\n",
    "\n",
    "    # Perform search against Pinecone\n",
    "    response = index.query(\n",
    "        namespace=\"__default__\",\n",
    "        vector=embedding, \n",
    "        top_k=3,\n",
    "        include_metadata=True,\n",
    "        include_values=False\n",
    "    )\n",
    "\n",
    "    response = response.to_dict()\n",
    "    \n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{response['matches']}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52542fc-18cf-45de-882a-b21d4b772b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "messages = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is Moncler?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "result = agent.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3401045a-30bf-497e-b301-5f8a7cf72ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided context does not include information about Moncler. However, Moncler is a luxury fashion brand known for its high-end outerwear, particularly its down jackets and skiwear. It was founded in 1952 in Italy and has become popular worldwide for its stylish and functional clothing. If you would like, I can help find more detailed information about Moncler.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a545e34-223d-4906-8f51-86fa02f3293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short-term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30881dbe-b8a0-4a45-a985-e4a1edd3b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context], checkpointer=InMemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a939b759-ce83-48d0-9cfe-1b1c23c81e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"I live in California\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "result = agent.invoke(messages, {\"configurable\": {\"thread_id\": \"1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a19c54fc-cae5-42cb-9518-d82c9915207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Thank you for sharing that you live in California! Is there anything specific you would like to know or discuss about California?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 386, 'total_tokens': 410, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CWGhEwx16QtacanFaEFGqkG0WoF57', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--9a450319-21d7-4f6c-89b5-af42e1378bd7-0' usage_metadata={'input_tokens': 386, 'output_tokens': 24, 'total_tokens': 410, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fad31fd6-b80a-45a6-b5b2-b8d9fb6d1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing chat using multiple namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d77e65-99bd-417e-a91a-b28cea67c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add record to new namespace\n",
    "\n",
    "# Create a sample dataset\n",
    "\n",
    "records = [\n",
    "    { \"_id\": \"rec1\", \"chunk_text\": \"Palantir Technologies Inc. is an American publicly traded company specializing in software platforms for data. Headquartered in Denver, Colorado, it was founded in 2003 by Peter Thiel, Stephen Cohen, Joe Lonsdale, Alex Karp, and Nathan Gettings. The current revenue for Palantir in 2024 is $2.87 billion, and their total net income is $462 million (2024). They currently have 3,936 employees (2024).\", \"category\": \"business\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8b2c71-8af0-4b8f-aac7-ca98897ac61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"text-embedding-3-large\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=model_name, api_key=config['OPEN_AI_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab49d758-55d5-4274-92bd-c1d900b9e14e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:13:26.409259Z",
     "start_time": "2025-12-02T09:13:25.219788Z"
    }
   },
   "source": [
    "# Function to embed text > to feed to Pinecone index.query\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Generates a vector embedding for the given text using OpenAI's model.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \") # Best practice is to replace newlines\n",
    "    response = client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    # The embedding is in the 'data' array of the response\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"The Rolex Yachtmaster 40 was first released in 1992. The current reference number 126622 is $12,500 USD. It features a 40 mm oyster case in oystersteel and platinum.\"\n",
    "embedding_vector = get_embedding(sentence)\n",
    "\n",
    "print(f\"Original sentence: {sentence}\")\n",
    "print(f\"Embedding vector (first 50 dimensions): {embedding_vector[:50]}...\")\n",
    "print(f\"Vector dimension: {len(embedding_vector)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: The Rolex Yachtmaster 40 was first released in 1992. The current reference number 126622 is $12,500 USD. It features a 40 mm oyster case in oystersteel and platinum.\n",
      "Embedding vector (first 50 dimensions): [0.006935261655598879, 0.037173446267843246, -0.013058535754680634, 0.03287992626428604, -0.036461565643548965, -0.048808224499225616, -0.016795901581645012, 0.03497106954455376, -0.029454005882143974, -0.01055583544075489, -0.00029424112290143967, 0.0012916716514155269, 0.03216804563999176, 0.002591685624793172, 0.037039969116449356, -0.017574520781636238, -0.008014203980565071, -0.0106058893725276, -0.09645964205265045, -5.852669710293412e-05, -0.03975400701165199, -0.022457566112279892, -0.041266750544309616, 0.009348977357149124, -0.02776329219341278, -0.008164365775883198, -0.006896330509334803, -0.002861421089619398, 0.005124974530190229, -0.018219660967588425, 0.0003378645924385637, -0.009421277791261673, -0.04707301780581474, 0.03474860638380051, -0.008231104351580143, 0.01612851582467556, -0.00835901964455843, -0.028764372691512108, 0.00752478651702404, -0.06042075529694557, 0.015839314088225365, 0.0348820835351944, -0.004376945085823536, 0.0026250549126416445, 0.0419786311686039, -0.05339094623923302, -0.04362485185265541, 0.04222334176301956, -0.028452925384044647, 0.029276035726070404]...\n",
      "Vector dimension: 3072\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "47bff2c8-cdfd-4b68-b6c2-399af508edaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:10:54.239485Z",
     "start_time": "2025-12-02T09:10:54.200589Z"
    }
   },
   "source": [
    "index = pc.Index(host=\"https://test-index-3-kuv1rfi.svc.aped-4627-b74a.pinecone.io\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramaka/Desktop/Projects/LangChain/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "ca4b8947-3bdd-45bc-9b7f-d5f07e41c02e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:13:38.094293Z",
     "start_time": "2025-12-02T09:13:37.211098Z"
    }
   },
   "source": [
    "index.upsert(\n",
    "    vectors=[{\n",
    "        \"id\": \"rec1\",\n",
    "        \"values\": embedding_vector,\n",
    "        \"metadata\": {\n",
    "            \"category\": \"business\",\n",
    "            \"text\": sentence\n",
    "        }\n",
    "    }],\n",
    "    namespace=\"text\"\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e622f22b-56c0-4f46-9360-e6710a705913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multiple context in chat model"
   ]
  },
  {
   "cell_type": "code",
   "id": "5a75ed66-3c35-4863-9721-8bc5d62fb55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:13:59.522181Z",
     "start_time": "2025-12-02T09:13:58.659736Z"
    }
   },
   "source": [
    "sentence = \"What is the Rolex Yachtmaster?\"\n",
    "\n",
    "sentence_embedding = get_embedding(sentence)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "10bf09c4-7bab-4865-97d8-a4f702ed0ef9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T09:14:05.218586Z",
     "start_time": "2025-12-02T09:14:04.745673Z"
    }
   },
   "source": [
    "# Pinecone - Debug\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))\n",
    "\n",
    "# To get the unique host for an index, \n",
    "# see https://docs.pinecone.io/guides/manage-data/target-an-index\n",
    "index = pc.Index(host=\"https://test-index-3-kuv1rfi.svc.aped-4627-b74a.pinecone.io\")\n",
    "\n",
    "response = index.query(\n",
    "    namespace=\"text\",\n",
    "    vector=sentence_embedding, \n",
    "    top_k=3,\n",
    "    include_metadata=True,\n",
    "    include_values=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d32122dc-5897-44e2-8a2c-363e4a5d9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6a6dcf3-876a-47e8-91fe-e641369881c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'ba5eac1d-b1b3-42a2-a6cf-4803afe2fddd',\n",
       "  'metadata': {'_id': 'rec52',\n",
       "               'category': 'business',\n",
       "               'text': 'Palantir is a software company specializing in data '\n",
       "                       'analytics and integration platforms, primarily serving '\n",
       "                       'government and commercial clients. Its technology, '\n",
       "                       'including the platforms Gotham and Foundry, helps '\n",
       "                       'organizations analyze and integrate data from disparate '\n",
       "                       'sources to improve decision-making.'},\n",
       "  'score': 0.468770981,\n",
       "  'values': []},\n",
       " {'id': '34e9e4b6-51ee-4de0-b080-399104d92073',\n",
       "  'metadata': {'_id': 'rec11',\n",
       "               'category': 'biology',\n",
       "               'text': 'The human brain has approximately 86 billion neurons.'},\n",
       "  'score': 0.175664902,\n",
       "  'values': []},\n",
       " {'id': 'aeba9edb-e734-4e94-a281-cb3cc5213e34',\n",
       "  'metadata': {'_id': 'rec51',\n",
       "               'category': 'business',\n",
       "               'text': 'Maka Projects is a holding company that owns multiple '\n",
       "                       'multi-billion dollar companies including Chedr, Gymogul '\n",
       "                       'and Coach Central.'},\n",
       "  'score': 0.158891693,\n",
       "  'values': []},\n",
       " [{'id': 'rec1',\n",
       "   'metadata': {'category': 'business',\n",
       "                'text': 'Palantir Technologies Inc. is an American publicly '\n",
       "                        'traded company specializing in software platforms for '\n",
       "                        'data. Headquartered in Denver, Colorado, it was founded '\n",
       "                        'in 2003 by Peter Thiel, Stephen Cohen, Joe Lonsdale, '\n",
       "                        'Alex Karp, and Nathan Gettings. The current revenue for '\n",
       "                        'Palantir in 2024 is $2.87 billion, and their total net '\n",
       "                        'income is $462 million (2024). They currently have '\n",
       "                        '3,936 employees (2024).'},\n",
       "   'score': 0.661186218,\n",
       "   'values': []}]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16a2b57b-e105-48fd-a3ac-ba401e419cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'rec1',\n",
       "  'metadata': {'category': 'business',\n",
       "               'text': 'Palantir Technologies Inc. is an American publicly '\n",
       "                       'traded company specializing in software platforms for '\n",
       "                       'data. Headquartered in Denver, Colorado, it was founded '\n",
       "                       'in 2003 by Peter Thiel, Stephen Cohen, Joe Lonsdale, '\n",
       "                       'Alex Karp, and Nathan Gettings. The current revenue for '\n",
       "                       'Palantir in 2024 is $2.87 billion, and their total net '\n",
       "                       'income is $462 million (2024). They currently have '\n",
       "                       '3,936 employees (2024).'},\n",
       "  'score': 0.661186218,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7fbfa59-8d62-4d63-aebd-2cd2793bb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_3 = response_1['matches'] + response_2['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3b83179-6952-4d73-913d-7ae72c5a633d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'ba5eac1d-b1b3-42a2-a6cf-4803afe2fddd',\n",
       "  'metadata': {'_id': 'rec52',\n",
       "               'category': 'business',\n",
       "               'text': 'Palantir is a software company specializing in data '\n",
       "                       'analytics and integration platforms, primarily serving '\n",
       "                       'government and commercial clients. Its technology, '\n",
       "                       'including the platforms Gotham and Foundry, helps '\n",
       "                       'organizations analyze and integrate data from disparate '\n",
       "                       'sources to improve decision-making.'},\n",
       "  'score': 0.468770981,\n",
       "  'values': []},\n",
       " {'id': '34e9e4b6-51ee-4de0-b080-399104d92073',\n",
       "  'metadata': {'_id': 'rec11',\n",
       "               'category': 'biology',\n",
       "               'text': 'The human brain has approximately 86 billion neurons.'},\n",
       "  'score': 0.175664902,\n",
       "  'values': []},\n",
       " {'id': 'aeba9edb-e734-4e94-a281-cb3cc5213e34',\n",
       "  'metadata': {'_id': 'rec51',\n",
       "               'category': 'business',\n",
       "               'text': 'Maka Projects is a holding company that owns multiple '\n",
       "                       'multi-billion dollar companies including Chedr, Gymogul '\n",
       "                       'and Coach Central.'},\n",
       "  'score': 0.158891693,\n",
       "  'values': []},\n",
       " [{'id': 'rec1',\n",
       "   'metadata': {'category': 'business',\n",
       "                'text': 'Palantir Technologies Inc. is an American publicly '\n",
       "                        'traded company specializing in software platforms for '\n",
       "                        'data. Headquartered in Denver, Colorado, it was founded '\n",
       "                        'in 2003 by Peter Thiel, Stephen Cohen, Joe Lonsdale, '\n",
       "                        'Alex Karp, and Nathan Gettings. The current revenue for '\n",
       "                        'Palantir in 2024 is $2.87 billion, and their total net '\n",
       "                        'income is $462 million (2024). They currently have '\n",
       "                        '3,936 employees (2024).'},\n",
       "   'score': 0.661186218,\n",
       "   'values': []}],\n",
       " {'id': 'rec1',\n",
       "  'metadata': {'category': 'business',\n",
       "               'text': 'Palantir Technologies Inc. is an American publicly '\n",
       "                       'traded company specializing in software platforms for '\n",
       "                       'data. Headquartered in Denver, Colorado, it was founded '\n",
       "                       'in 2003 by Peter Thiel, Stephen Cohen, Joe Lonsdale, '\n",
       "                       'Alex Karp, and Nathan Gettings. The current revenue for '\n",
       "                       'Palantir in 2024 is $2.87 billion, and their total net '\n",
       "                       'income is $462 million (2024). They currently have '\n",
       "                       '3,936 employees (2024).'},\n",
       "  'score': 0.661186218,\n",
       "  'values': []},\n",
       " {'id': 'rec1',\n",
       "  'metadata': {'category': 'business',\n",
       "               'text': 'Palantir Technologies Inc. is an American publicly '\n",
       "                       'traded company specializing in software platforms for '\n",
       "                       'data. Headquartered in Denver, Colorado, it was founded '\n",
       "                       'in 2003 by Peter Thiel, Stephen Cohen, Joe Lonsdale, '\n",
       "                       'Alex Karp, and Nathan Gettings. The current revenue for '\n",
       "                       'Palantir in 2024 is $2.87 billion, and their total net '\n",
       "                       'income is $462 million (2024). They currently have '\n",
       "                       '3,936 employees (2024).'},\n",
       "  'score': 0.661186218,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "277cd88c-4994-4293-b395-acc6402b2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3\n",
    "\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    \n",
    "    # Get embedding for message\n",
    "    embedding = get_embedding(last_query)\n",
    "\n",
    "    # Perform search against Pinecone\n",
    "    response_1 = index.query(\n",
    "        namespace=\"__default__\",\n",
    "        vector=embedding, \n",
    "        top_k=3,\n",
    "        include_metadata=True,\n",
    "        include_values=False\n",
    "    )\n",
    "\n",
    "    response_2 = index.query(\n",
    "        namespace=\"text\",\n",
    "        vector=embedding, \n",
    "        top_k=3,\n",
    "        include_metadata=True,\n",
    "        include_values=False\n",
    "    )\n",
    "\n",
    "    response = response_1['matches'] + response_2['matches']\n",
    "    \n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{response}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be50da34-d422-49d6-8bb1-ad867ed63464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "messages = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is Palantir and as of 2024, how many employees did they employ?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "result = agent.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b029ce4-5241-462d-a49f-9d492402eb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Palantir and as of 2024, how many employees did they employ?', additional_kwargs={}, response_metadata={}, id='79268b22-c269-49c6-bb61-1ca2fe31d695'),\n",
       "  AIMessage(content='Palantir is a software company specializing in data analytics and integration platforms, primarily serving government and commercial clients. Its technology, including the platforms Gotham and Foundry, helps organizations analyze and integrate data from disparate sources to improve decision-making. As of 2024, Palantir employed 3,936 employees.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 504, 'total_tokens': 567, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CdO7WyBt0IXzsDtyqcxhWlID9OjNL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--96405271-86d4-4a55-8908-1e7694de159f-0', usage_metadata={'input_tokens': 504, 'output_tokens': 63, 'total_tokens': 567, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b83649-263e-4565-bc4c-717c0f3a2a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
